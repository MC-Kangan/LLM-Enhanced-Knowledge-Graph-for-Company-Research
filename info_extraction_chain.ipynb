{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "from firecrawl_scraping import *\n",
    "from utility import *\n",
    "from llm_extraction import *\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import tiktoken\n",
    "import instructor\n",
    "from pydantic import BaseModel\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gpt-4o: \"o200k_base\",\n",
    "- gpt-4: \"cl100k_base\",\n",
    "- gpt-3.5-turbo: \"cl100k_base\",\n",
    "- gpt-3.5: \"cl100k_base\",  # Common shorthand\n",
    "- gpt-35-turbo : \"cl100k_base\",  # Azure deployment name\n",
    "\n",
    "gpt-4o US$5.00 / 1M input tokens； US$15.00 / 1M output tokens\n",
    "\n",
    "gpt-4o context length: 128K tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Encoding 'o200k_base'>\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>processed_name</th>\n",
       "      <th>url</th>\n",
       "      <th>related_urls_str</th>\n",
       "      <th>related_urls</th>\n",
       "      <th>num_of_related_urls</th>\n",
       "      <th>all_urls</th>\n",
       "      <th>num_of_all_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vertice</td>\n",
       "      <td>vertice</td>\n",
       "      <td>https://www.vertice.one</td>\n",
       "      <td>https://www.vertice.one/product/saas-purchasin...</td>\n",
       "      <td>['https://www.vertice.one/product/saas-purchas...</td>\n",
       "      <td>6</td>\n",
       "      <td>['https://www.vertice.one/explore/cloud-manage...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Massive</td>\n",
       "      <td>massive</td>\n",
       "      <td>https://www.joinmassive.com</td>\n",
       "      <td>https://www.joinmassive.com/casestudies,https:...</td>\n",
       "      <td>['https://www.joinmassive.com/casestudies', 'h...</td>\n",
       "      <td>3</td>\n",
       "      <td>['https://www.joinmassive.com/faq#users', 'htt...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Additive</td>\n",
       "      <td>additive</td>\n",
       "      <td>https://www.additive.ai</td>\n",
       "      <td>https://www.additive.ai</td>\n",
       "      <td>['https://www.additive.ai']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.additive.ai', 'https://www.addit...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Nexben</td>\n",
       "      <td>nexben</td>\n",
       "      <td>https://www.nexben.com</td>\n",
       "      <td>https://www.nexben.com/payment-solutions/ichra...</td>\n",
       "      <td>['https://www.nexben.com/payment-solutions/ich...</td>\n",
       "      <td>16</td>\n",
       "      <td>['https://www.nexben.com/about/meet-the-team',...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>https://www.directsoftware.com</td>\n",
       "      <td>https://www.directsoftware.com/partners,https:...</td>\n",
       "      <td>['https://www.directsoftware.com/partners', 'h...</td>\n",
       "      <td>13</td>\n",
       "      <td>['https://www.directsoftware.com/partners', 'h...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Ledger Works</td>\n",
       "      <td>ledger_works</td>\n",
       "      <td>https://www.lworks.io</td>\n",
       "      <td>https://www.lworks.io/customers-partners,https...</td>\n",
       "      <td>['https://www.lworks.io/customers-partners', '...</td>\n",
       "      <td>10</td>\n",
       "      <td>['https://www.lworks.io/customers-partners', '...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Vesta</td>\n",
       "      <td>vesta</td>\n",
       "      <td>https://www.vesta.com</td>\n",
       "      <td>https://www.vesta.com/partners,https://www.ves...</td>\n",
       "      <td>['https://www.vesta.com/partners', 'https://ww...</td>\n",
       "      <td>3</td>\n",
       "      <td>['https://www.vesta.com/privacy', 'https://www...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Niloom.ai</td>\n",
       "      <td>niloom_ai</td>\n",
       "      <td>https://www.niloom.ai</td>\n",
       "      <td>https://www.niloom.ai</td>\n",
       "      <td>['https://www.niloom.ai']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.niloom.ai', 'https://www.niloom....</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Hemlane</td>\n",
       "      <td>hemlane</td>\n",
       "      <td>https://www.hemlane.com</td>\n",
       "      <td>https://www.hemlane.com/realtor-partners/,http...</td>\n",
       "      <td>['https://www.hemlane.com/realtor-partners/', ...</td>\n",
       "      <td>2</td>\n",
       "      <td>['https://www.hemlane.com/features/rental-adve...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Harness Data Intelligence</td>\n",
       "      <td>harness_data_intelligence</td>\n",
       "      <td>https://www.harnessproperty.com</td>\n",
       "      <td>https://www.harnessproperty.com/search/service...</td>\n",
       "      <td>['https://www.harnessproperty.com/search/servi...</td>\n",
       "      <td>2</td>\n",
       "      <td>['https://www.harnessproperty.com/contact-us',...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Dexit</td>\n",
       "      <td>dexit</td>\n",
       "      <td>https://www.dexitcorp.com</td>\n",
       "      <td>https://www.dexitcorp.com/services,https://www...</td>\n",
       "      <td>['https://www.dexitcorp.com/services', 'https:...</td>\n",
       "      <td>2</td>\n",
       "      <td>['https://www.dexitcorp.com/contact-us', 'http...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>NatureAlpha</td>\n",
       "      <td>naturealpha</td>\n",
       "      <td>https://www.naturealpha.ai</td>\n",
       "      <td>https://www.naturealpha.ai/solutions,https://w...</td>\n",
       "      <td>['https://www.naturealpha.ai/solutions', 'http...</td>\n",
       "      <td>2</td>\n",
       "      <td>['https://www.naturealpha.ai', 'https://www.na...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Missionmark</td>\n",
       "      <td>missionmark</td>\n",
       "      <td>https://www.missionmark.com</td>\n",
       "      <td>https://www.missionmark.com/template/resources...</td>\n",
       "      <td>['https://www.missionmark.com/template/resourc...</td>\n",
       "      <td>3</td>\n",
       "      <td>['https://www.missionmark.com/features/time-tr...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Bennie</td>\n",
       "      <td>bennie</td>\n",
       "      <td>https://www.bennie.com</td>\n",
       "      <td>https://www.bennie.com/customers,https://www.b...</td>\n",
       "      <td>['https://www.bennie.com/customers', 'https://...</td>\n",
       "      <td>3</td>\n",
       "      <td>['https://www.bennie.com/privacy-policy', 'htt...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Infogrid</td>\n",
       "      <td>infogrid</td>\n",
       "      <td>https://www.infogrid.io</td>\n",
       "      <td>https://www.infogrid.io/solutions,https://www....</td>\n",
       "      <td>['https://www.infogrid.io/solutions', 'https:/...</td>\n",
       "      <td>4</td>\n",
       "      <td>['https://www.infogrid.io#page', 'https://www....</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>New Constructs</td>\n",
       "      <td>new_constructs</td>\n",
       "      <td>https://www.newconstructs.com</td>\n",
       "      <td>https://www.newconstructs.com/customer-testimo...</td>\n",
       "      <td>['https://www.newconstructs.com/customer-testi...</td>\n",
       "      <td>3</td>\n",
       "      <td>['https://www.newconstructs.com', 'https://www...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>9fin</td>\n",
       "      <td>9fin</td>\n",
       "      <td>https://www.9fin.com</td>\n",
       "      <td>https://www.9fin.com/solutions/asset-managers-...</td>\n",
       "      <td>['https://www.9fin.com/solutions/asset-manager...</td>\n",
       "      <td>6</td>\n",
       "      <td>['https://www.9fin.com/solutions/asset-manager...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Adaptive</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>https://www.adaptive.build</td>\n",
       "      <td>https://www.adaptive.build/case-studies,https:...</td>\n",
       "      <td>['https://www.adaptive.build/case-studies', 'h...</td>\n",
       "      <td>2</td>\n",
       "      <td>['https://www.adaptive.build', 'https://www.ad...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Estimize</td>\n",
       "      <td>estimize</td>\n",
       "      <td>https://www.estimize.com</td>\n",
       "      <td>https://www.estimize.com</td>\n",
       "      <td>['https://www.estimize.com']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.estimize.com']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>Aer Compliance</td>\n",
       "      <td>aer_compliance</td>\n",
       "      <td>https://www.aercompliance.com</td>\n",
       "      <td>https://www.aercompliance.com/solution/firm-tr...</td>\n",
       "      <td>['https://www.aercompliance.com/solution/firm-...</td>\n",
       "      <td>12</td>\n",
       "      <td>['https://www.aercompliance.com/solution/firm-...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       company             processed_name  \\\n",
       "5                      Vertice                    vertice   \n",
       "6                      Massive                    massive   \n",
       "14                    Additive                   additive   \n",
       "105                     Nexben                     nexben   \n",
       "142                     Direct                     direct   \n",
       "168               Ledger Works               ledger_works   \n",
       "196                      Vesta                      vesta   \n",
       "197                  Niloom.ai                  niloom_ai   \n",
       "226                    Hemlane                    hemlane   \n",
       "247  Harness Data Intelligence  harness_data_intelligence   \n",
       "261                      Dexit                      dexit   \n",
       "295                NatureAlpha                naturealpha   \n",
       "347                Missionmark                missionmark   \n",
       "363                     Bennie                     bennie   \n",
       "498                   Infogrid                   infogrid   \n",
       "519             New Constructs             new_constructs   \n",
       "653                       9fin                       9fin   \n",
       "660                   Adaptive                   adaptive   \n",
       "681                   Estimize                   estimize   \n",
       "698             Aer Compliance             aer_compliance   \n",
       "\n",
       "                                 url  \\\n",
       "5            https://www.vertice.one   \n",
       "6        https://www.joinmassive.com   \n",
       "14           https://www.additive.ai   \n",
       "105           https://www.nexben.com   \n",
       "142   https://www.directsoftware.com   \n",
       "168            https://www.lworks.io   \n",
       "196            https://www.vesta.com   \n",
       "197            https://www.niloom.ai   \n",
       "226          https://www.hemlane.com   \n",
       "247  https://www.harnessproperty.com   \n",
       "261        https://www.dexitcorp.com   \n",
       "295       https://www.naturealpha.ai   \n",
       "347      https://www.missionmark.com   \n",
       "363           https://www.bennie.com   \n",
       "498          https://www.infogrid.io   \n",
       "519    https://www.newconstructs.com   \n",
       "653             https://www.9fin.com   \n",
       "660       https://www.adaptive.build   \n",
       "681         https://www.estimize.com   \n",
       "698    https://www.aercompliance.com   \n",
       "\n",
       "                                      related_urls_str  \\\n",
       "5    https://www.vertice.one/product/saas-purchasin...   \n",
       "6    https://www.joinmassive.com/casestudies,https:...   \n",
       "14                             https://www.additive.ai   \n",
       "105  https://www.nexben.com/payment-solutions/ichra...   \n",
       "142  https://www.directsoftware.com/partners,https:...   \n",
       "168  https://www.lworks.io/customers-partners,https...   \n",
       "196  https://www.vesta.com/partners,https://www.ves...   \n",
       "197                              https://www.niloom.ai   \n",
       "226  https://www.hemlane.com/realtor-partners/,http...   \n",
       "247  https://www.harnessproperty.com/search/service...   \n",
       "261  https://www.dexitcorp.com/services,https://www...   \n",
       "295  https://www.naturealpha.ai/solutions,https://w...   \n",
       "347  https://www.missionmark.com/template/resources...   \n",
       "363  https://www.bennie.com/customers,https://www.b...   \n",
       "498  https://www.infogrid.io/solutions,https://www....   \n",
       "519  https://www.newconstructs.com/customer-testimo...   \n",
       "653  https://www.9fin.com/solutions/asset-managers-...   \n",
       "660  https://www.adaptive.build/case-studies,https:...   \n",
       "681                           https://www.estimize.com   \n",
       "698  https://www.aercompliance.com/solution/firm-tr...   \n",
       "\n",
       "                                          related_urls  num_of_related_urls  \\\n",
       "5    ['https://www.vertice.one/product/saas-purchas...                    6   \n",
       "6    ['https://www.joinmassive.com/casestudies', 'h...                    3   \n",
       "14                         ['https://www.additive.ai']                    1   \n",
       "105  ['https://www.nexben.com/payment-solutions/ich...                   16   \n",
       "142  ['https://www.directsoftware.com/partners', 'h...                   13   \n",
       "168  ['https://www.lworks.io/customers-partners', '...                   10   \n",
       "196  ['https://www.vesta.com/partners', 'https://ww...                    3   \n",
       "197                          ['https://www.niloom.ai']                    1   \n",
       "226  ['https://www.hemlane.com/realtor-partners/', ...                    2   \n",
       "247  ['https://www.harnessproperty.com/search/servi...                    2   \n",
       "261  ['https://www.dexitcorp.com/services', 'https:...                    2   \n",
       "295  ['https://www.naturealpha.ai/solutions', 'http...                    2   \n",
       "347  ['https://www.missionmark.com/template/resourc...                    3   \n",
       "363  ['https://www.bennie.com/customers', 'https://...                    3   \n",
       "498  ['https://www.infogrid.io/solutions', 'https:/...                    4   \n",
       "519  ['https://www.newconstructs.com/customer-testi...                    3   \n",
       "653  ['https://www.9fin.com/solutions/asset-manager...                    6   \n",
       "660  ['https://www.adaptive.build/case-studies', 'h...                    2   \n",
       "681                       ['https://www.estimize.com']                    1   \n",
       "698  ['https://www.aercompliance.com/solution/firm-...                   12   \n",
       "\n",
       "                                              all_urls  num_of_all_urls  \n",
       "5    ['https://www.vertice.one/explore/cloud-manage...               31  \n",
       "6    ['https://www.joinmassive.com/faq#users', 'htt...               25  \n",
       "14   ['https://www.additive.ai', 'https://www.addit...                4  \n",
       "105  ['https://www.nexben.com/about/meet-the-team',...               32  \n",
       "142  ['https://www.directsoftware.com/partners', 'h...               16  \n",
       "168  ['https://www.lworks.io/customers-partners', '...               20  \n",
       "196  ['https://www.vesta.com/privacy', 'https://www...                9  \n",
       "197  ['https://www.niloom.ai', 'https://www.niloom....                7  \n",
       "226  ['https://www.hemlane.com/features/rental-adve...               31  \n",
       "247  ['https://www.harnessproperty.com/contact-us',...               31  \n",
       "261  ['https://www.dexitcorp.com/contact-us', 'http...               14  \n",
       "295  ['https://www.naturealpha.ai', 'https://www.na...                9  \n",
       "347  ['https://www.missionmark.com/features/time-tr...               15  \n",
       "363  ['https://www.bennie.com/privacy-policy', 'htt...               17  \n",
       "498  ['https://www.infogrid.io#page', 'https://www....               27  \n",
       "519  ['https://www.newconstructs.com', 'https://www...               24  \n",
       "653  ['https://www.9fin.com/solutions/asset-manager...               27  \n",
       "660  ['https://www.adaptive.build', 'https://www.ad...               13  \n",
       "681                       ['https://www.estimize.com']                1  \n",
       "698  ['https://www.aercompliance.com/solution/firm-...               20  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('companies_urls_info.csv')\n",
    "sample = df[df['url'].isin(['https://www.vertice.one', \n",
    "                   'https://www.estimize.com',\n",
    "                   'https://www.newconstructs.com',\n",
    "                   'https://www.chargebee.com',\n",
    "                   'https://www.bennie.com',\n",
    "                   'https://www.aercompliance.com',\n",
    "                   'https://www.missionmark.com',\n",
    "                   'https://www.joinmassive.com',\n",
    "                   'https://www.hemlane.com',\n",
    "                   'https://www.vesta.com',\n",
    "                   'https://www.adaptive.build',\n",
    "                   'https://www.additive.ai',\n",
    "                   'https://www.9fin.com',\n",
    "                   'https://www.niloom.ai',\n",
    "                   'https://www.nexben.com',\n",
    "                   'https://www.naturealpha.ai',\n",
    "                   'https://www.lworks.io',\n",
    "                   'https://www.infogrid.io',\n",
    "                   'https://www.harnessproperty.com',\n",
    "                   'https://www.directsoftware.com',\n",
    "                   'https://www.dexitcorp.com'])]\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "def crawl_data(base_url, url_list: list, file_path: str, overwrite: bool = False):\n",
    "    load_dotenv()\n",
    "    # Initialize the FirecrawlApp with your API key\n",
    "    app = FirecrawlApp(api_key=os.getenv('FIRECRAWL_KEY'))\n",
    "    \n",
    "    # Load existing data if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            result = json.load(file)\n",
    "    else:\n",
    "        result = {}\n",
    "\n",
    "    rate_limit_reset_time = 0\n",
    "    \n",
    "    for url in url_list:\n",
    "        # Determine the endpoint\n",
    "        if base_url == url:\n",
    "            endpoint = 'main_page'\n",
    "        else:\n",
    "            if base_url in url:\n",
    "                endpoint = url.replace(base_url, '')\n",
    "            else:\n",
    "                endpoint = url\n",
    "        \n",
    "        # Check if the endpoint already exists in the result\n",
    "        if endpoint in result and not overwrite:\n",
    "            print(f\"Skipping {url} as it already exists and overwrite is set to False.\")\n",
    "            continue  # Skip this URL and move to the next one\n",
    "\n",
    "        # Respect rate limit by waiting until the reset time\n",
    "        if time.time() < rate_limit_reset_time:\n",
    "            wait_time = rate_limit_reset_time - time.time()\n",
    "            print(f\"Rate limit exceeded. Waiting for {wait_time} seconds.\")\n",
    "            time.sleep(wait_time)\n",
    "        \n",
    "        try:\n",
    "            # Scrape a single URL\n",
    "            print(f\"Scraping {url}.\")\n",
    "            response = app.scrape_url(url, {'pageOptions': {'onlyMainContent': True}})\n",
    "            \n",
    "            try:\n",
    "                scraped_data = response.json()  # Attempt to parse JSON response\n",
    "            except ValueError:\n",
    "                print(f\"Failed to decode JSON response for {url}\")\n",
    "                continue  # Skip to the next URL\n",
    "\n",
    "            # Check if 'markdown' key exists in the scraped data\n",
    "            if 'markdown' in scraped_data:\n",
    "                result[endpoint] = scraped_data['markdown']\n",
    "        \n",
    "        except HTTPError as e:\n",
    "            # Handle rate limit exceeded error\n",
    "            if e.response.status_code == 429:\n",
    "                rate_limit_reset_time = int(e.response.headers.get('Retry-After', 60)) + time.time()\n",
    "                print(f\"Rate limit exceeded. Retrying after {rate_limit_reset_time - time.time()} seconds.\")\n",
    "                time.sleep(rate_limit_reset_time - time.time())\n",
    "                continue  # Skip the rest of the code in this iteration and retry scraping the same URL\n",
    "            else:\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "    \n",
    "    # Write the updated JSON data back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(result, file, indent=4)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "# result = crawl_data(base_url, url_list, 'scraped_data.json', overwrite=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.joinmassive.com/casestudies as it already exists and overwrite is set to False.\n",
      "Skipping https://www.joinmassive.com/partners as it already exists and overwrite is set to False.\n",
      "Skipping https://www.joinmassive.com as it already exists and overwrite is set to False.\n",
      "Scraping https://www.additive.ai.\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/requests/models.py:974\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m base_url \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m url_list \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelated_urls\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcrawl_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscraping_output_v2_raw/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprocessed_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UCL DSML/Thesis/project/firecrawl_scraping.py:91\u001b[0m, in \u001b[0;36mcrawl_data\u001b[0;34m(base_url, url_list, file_path, overwrite)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Scrape a single URL\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScraping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m     scraped_data \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpageOptions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43monlyMainContent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# Check if 'markdown' key exists in the scraped data\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m scraped_data:\n",
      "File \u001b[0;32m~/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/firecrawl/firecrawl.py:91\u001b[0m, in \u001b[0;36mFirecrawlApp.scrape_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to scrape URL. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscrape URL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/firecrawl/firecrawl.py:303\u001b[0m, in \u001b[0;36mFirecrawlApp._handle_error\u001b[0;34m(self, response, action)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, response: requests\u001b[38;5;241m.\u001b[39mResponse, action: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    Handle errors from API responses.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m        Exception: An exception with a message containing the status code and error details from the response.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo additional error details provided.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m402\u001b[39m:\n\u001b[1;32m    306\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPayment Required: Failed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/requests/models.py:978\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "for index, row in sample.iloc[1:].iterrows():\n",
    "    base_url = row['url']\n",
    "    url_list = ast.literal_eval(row['related_urls'])\n",
    "    result = crawl_data(base_url, url_list, f'scraping_output_v2_raw/{row[\"processed_name\"]}.json', overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = scrape_data('https://www.vertice.one/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Talk to a human: [(866) 387-1629]\n",
      "[Sign in]\n",
      "REALTORS®' Partner in Property Management\n",
      "**The best agents** help their clients get the most out of their rental properties.\n",
      "![Voted Capterra's Top 20 Property Management Solutions]![Software Advice most recommended Property Management Solution badge]![Software Advice Real Estate Property Management Front Runner Badge]![Software Advice Badge - Best Customer Support for Property Management]![GetApp Badge - Best Functionality and Features]\n",
      "Back\n",
      "How do you support your clients with their rental properties?\n",
      "I want to refer landlords\n",
      "(and get paid for it)\n",
      "I offer leasing\n",
      "(and want free leads and tools)\n",
      "I offer property management\n",
      "(and want to eliminate trust accounts)\n",
      "Check out other REALTORS® partnering with us\n",
      "![]![Headshot of Timothy Hampson]\n",
      "Timothy Hampson\n",
      "License #9008072 (TX)\n",
      "HP2 RESIDENTIAL\n",
      "Experience\n",
      "Leasing\n",
      "12 years\n",
      "Management\n",
      "Real estate\n",
      "![]![Headshot of Sandy Wickware]\n",
      "Sandy Wickware\n",
      "License #253554 (TX)\n",
      "Fathom Realty, LLC\n",
      "14 years\n",
      "2 years\n",
      "![]![Headshot of Kadee McGwier]\n",
      "Kadee McGwier\n",
      "License #SP43079 (ID), #135248 (WA), #RRE-RBS-LIC-98863 (MT)\n",
      "B Wright At Home LLC\n",
      "5 years\n",
      "7 years\n",
      "...and many more.\n",
      "Not ready to try any of these today but want us to market your services for free?\n",
      "[Create your free agent profile]\n"
     ]
    }
   ],
   "source": [
    "data = read_json_file('scraping_output_v2_raw/hemlane.json')\n",
    "\n",
    "print(clean_scraped_content(data['/realtor-partners/']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/realtor-partners/\n",
      "Estimated GPT4-o cost: $0.08219499999999999\n",
      "Estimated GPT4-o cost after cleaning: $0.00167\n",
      "------------------------\n",
      "main_page\n",
      "Estimated GPT4-o cost: $0.01288\n",
      "Estimated GPT4-o cost after cleaning: $0.005535\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for url, content in data.items():\n",
    "    print(url)\n",
    "    print(f'Estimated GPT4-o cost: ${calculate_cost(data[url])}')\n",
    "    print(f'Estimated GPT4-o cost after cleaning: ${calculate_cost(clean_scraped_content(data[url]))}')\n",
    "    print('------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of first shorten the page by extracting relevant information\n",
    "Issue: The output of the content might be shorten too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def llm_summary(text, model_name=\"gpt-4o\"):\n",
    "    system_message = \"\"\"\n",
    "    You are an intelligent text extraction and conversion assistant. Your task is to extract information \n",
    "    from the given text and convert it into a text (string) format. \n",
    "    The output response should contain only the data extracted from the text, with no additional commentary, explanations, or extraneous information.\n",
    "    If the required information could not be found from the given source, return nothing. Do not hallucinate.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the extraction prompt\n",
    "    extraction_prompt = \"\"\"\n",
    "    You are provided with a text obtained from a company's webpage. Your task is to extract any sections or paragraphs that are relevant to the specified information of interest.\n",
    "\n",
    "    ## Information of Interest:\n",
    "\n",
    "    1. **About Product or Service**:\n",
    "    - Any details about the products or services the company offers, including their features.\n",
    "\n",
    "    2. **About Partner or Client**:\n",
    "    - Any information about the company's partners or clients.\n",
    "    - Any use cases (case studies) describing how a client is using the company's product or service.\n",
    "    \n",
    "    ## Note:\n",
    "    Sometimes, the company does not explicit describe their clients and the client use case, instead, they will only display clients' logos. \n",
    "    You then need to extract client's name from their logos. \n",
    "    \n",
    "    ## Instructions:\n",
    "    - Do not summarize the content. Extract the raw lines or sections as they are.\n",
    "    - If you are unsure about the relevance of the information, include it to ensure comprehensive coverage.\n",
    "    - Output the extracted information in standard text format.\n",
    "\n",
    "    ## Examples:\n",
    "\n",
    "    ### Example 1: Product or Service\n",
    "    If the input text contains:\n",
    "    \"Our company offers innovative cloud solutions that help businesses streamline their operations. Our key features include scalability, security, and ease of use.\n",
    "    We partner with leading firms such as TechCorp and SoftInc to deliver top-notch services.\"\n",
    "\n",
    "    The output should be:\n",
    "    \"Our company offers innovative cloud solutions that help businesses streamline their operations. Our key features include scalability, security, and ease of use.\n",
    "    We partner with leading firms such as TechCorp and SoftInc to deliver top-notch services.\"\n",
    "\n",
    "    ### Example 2: Client Logos\n",
    "    If the input text contains:\n",
    "    \"Our platform and service is trusted by these innovative companies:\n",
    "    ![Nationwide Logo]\n",
    "    ![Freedom 365 Logo]\n",
    "    ![Bestow Logo]\n",
    "    ...\"\n",
    "    \n",
    "    The output should be:\n",
    "    \"Our platform and service is trusted by these innovative companies: \n",
    "    Clients are: Nationwide, Freedom 365, Bestow...\"\n",
    "   \n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_message),\n",
    "            (\"system\", extraction_prompt),\n",
    "            (\"human\", \"Use the given text to extract information: {input}\"),\n",
    "            (\"human\", \"\"\"\n",
    "                Here are the rules that you need to adhere:\n",
    "                ## Rules:\n",
    "                - Make sure to answer in the standard text format.\n",
    "                - If no information is provided, return nothing.\n",
    "                - DO NOT HALLUCINATE.\n",
    "             \"\"\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    llm = ChatOpenAI(openai_api_key=os.getenv('OPENAI_KEY'),\n",
    "                    temperature=0, \n",
    "                    model_name=model_name)\n",
    "\n",
    "    llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    response = llm_chain.invoke({'input': text})\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "def llm_summary_execution(process_company_name:str, overwrite:bool = False):\n",
    "\n",
    "    scrape_file_path = f'scraping_output_v2_raw/{process_company_name}.json'\n",
    "    extraction_file_path = f'extraction_summary/{process_company_name}_summary_str.json'\n",
    "\n",
    "    scrape_data = read_json_file(scrape_file_path)\n",
    "\n",
    "    # Load existing data if the file exists\n",
    "    if os.path.exists(extraction_file_path):\n",
    "        with open(extraction_file_path, 'r') as file:\n",
    "            extracted_data = json.load(file)\n",
    "    else:\n",
    "        extracted_data = {}\n",
    "\n",
    "    for endpoint, content in tqdm(scrape_data.items(), total=len(scrape_data), desc=\"Extracting data\", position=0, leave=True):\n",
    "        if endpoint in extracted_data and not overwrite:\n",
    "            print(f\"Company: {process_company_name}; Skipping {endpoint} as it already exists and overwrite is set to False.\")\n",
    "            continue  # Skip this URL and move to the next one\n",
    "        else:\n",
    "            clean_content = clean_scraped_content(content)\n",
    "            extracted_data[endpoint] = llm_summary(clean_content)\n",
    "            print(f'Company: {process_company_name}; Content in {endpoint} is extracted.')\n",
    "            \n",
    "    write_json_file(f'extraction_summary/{process_company_name}_summary_str.json', extracted_data)\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "# # Example usage\n",
    "# extracted_data = {}\n",
    "# for key, value in data.items():\n",
    "#     clean_content = clean_scraped_content(value)\n",
    "#     extracted_data[key] = llm_summary(clean_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vertice',\n",
       " 'massive',\n",
       " 'vesta',\n",
       " 'hemlane',\n",
       " 'missionmark',\n",
       " 'bennie',\n",
       " 'new_constructs',\n",
       " 'aer_compliance']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['processed_name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data:  20%|██        | 1/5 [00:15<01:01, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /product/saas-purchasing is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data:  40%|████      | 2/5 [00:35<00:54, 18.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /product/cloud-cost-optimization is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data:  60%|██████    | 3/5 [00:39<00:22, 11.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /partners is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data:  80%|████████  | 4/5 [00:51<00:11, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /product/saas-cloud-platform is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data: 100%|██████████| 5/5 [00:57<00:00, 11.55s/it]\n",
      " 12%|█▎        | 1/8 [00:57<06:44, 57.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /customer-stories is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data:  33%|███▎      | 1/3 [00:02<00:04,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /casestudies is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data:  67%|██████▋   | 2/3 [00:04<00:02,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /partners is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data: 100%|██████████| 3/3 [00:14<00:00,  4.96s/it]\n",
      " 25%|██▌       | 2/8 [01:12<03:15, 32.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in main_page is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data:  50%|█████     | 1/2 [00:11<00:11, 11.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /partners is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data: 100%|██████████| 2/2 [00:22<00:00, 11.43s/it]\n",
      " 38%|███▊      | 3/8 [01:35<02:20, 28.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /product is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data: 100%|██████████| 2/2 [00:00<00:00, 25040.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /realtor-partners/ as it already exists and overwrite is set to False.\n",
      "Skipping main_page as it already exists and overwrite is set to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data:  33%|███▎      | 1/3 [00:05<00:11,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /template/resources/product is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data:  67%|██████▋   | 2/3 [00:16<00:08,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /template/services is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data: 100%|██████████| 3/3 [00:22<00:00,  7.55s/it]\n",
      " 62%|██████▎   | 5/8 [01:58<00:55, 18.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in main_page is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data: 100%|██████████| 3/3 [00:00<00:00, 63872.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /partners as it already exists and overwrite is set to False.\n",
      "Skipping /customers as it already exists and overwrite is set to False.\n",
      "Skipping main_page as it already exists and overwrite is set to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data:  33%|███▎      | 1/3 [00:06<00:13,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in main_page is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data:  67%|██████▋   | 2/3 [00:14<00:07,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /partnerships/ is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data: 100%|██████████| 3/3 [00:38<00:00, 12.78s/it]\n",
      " 88%|████████▊ | 7/8 [02:36<00:18, 18.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /customer-testimonials/ is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /solution/firm-trading as it already exists and overwrite is set to False.\n",
      "Skipping /solution/artificial-intelligence as it already exists and overwrite is set to False.\n",
      "Skipping /solution/best-in-class-coverage as it already exists and overwrite is set to False.\n",
      "Skipping /solution/pre-trade-clearance as it already exists and overwrite is set to False.\n",
      "Skipping /solutions as it already exists and overwrite is set to False.\n",
      "Skipping /solution/conflicts-of-interest as it already exists and overwrite is set to False.\n",
      "Skipping main_page as it already exists and overwrite is set to False.\n",
      "Skipping /solution/attestations-certifications as it already exists and overwrite is set to False.\n",
      "Skipping /solution/post-trade-monitoring as it already exists and overwrite is set to False.\n",
      "Skipping /solution/crypto as it already exists and overwrite is set to False.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data:  92%|█████████▏| 11/12 [00:07<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /industry/financial-services is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data: 100%|██████████| 12/12 [00:12<00:00,  1.04s/it]\n",
      "100%|██████████| 8/8 [02:48<00:00, 21.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content in /solution/cutting-edge-analytics-dashboards is extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for company in tqdm(sample['processed_name'].to_list()):\n",
    "    llm_summary_execution(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructor\n",
    "\n",
    "https://github.com/jxnl/instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "class ProductDescription(BaseModel):\n",
    "    name: str = Field(..., alias='summarised name of product')\n",
    "    description: str = Field(..., alias='concise features description of the product or service')\n",
    "    \n",
    "class SummaryProductDescription(BaseModel):\n",
    "    name: str = Field(..., alias='summarised name of the main product offerings of the company')\n",
    "    description: str = Field(..., alias='summary of product offering of the company')\n",
    "    \n",
    "class ClientDescription(BaseModel):\n",
    "    name: str = Field(..., alias='name of the client or partner')\n",
    "    product_used: Optional[str] = Field(None, alias='summary of the product or service used by the client or partner')\n",
    "    description: Optional[str] = Field(None, alias='description of the usecase')\n",
    "\n",
    "class ExtractedInformation(BaseModel):\n",
    "    product_descriptions: Optional[List[ProductDescription]] = None\n",
    "    # product_offering_summary: str = Field(..., alias='summary of product offering of the company')\n",
    "    summary_product_description: SummaryProductDescription\n",
    "    client_descriptions: Optional[List[ClientDescription]] = None\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_information_extraction(text: str, custom_extraction_prompt: str, model_name: str = 'gpt-4o') -> ExtractedInformation:\n",
    "    system_message = \"\"\"\n",
    "    You are an intelligent text extraction and conversion assistant. Your task is to extract structured information \n",
    "    from the given text and convert it into a structured format. \n",
    "    The output response should contain only the data extracted from the text, with no additional commentary, explanations, or extraneous information.\n",
    "    If the required information could not be found from the given source, return nothing for that field. Do not hallucinate.\n",
    "    \"\"\"\n",
    "    \n",
    "    extraction_prompt = f\"\"\"\n",
    "    {system_message}\n",
    "    {custom_extraction_prompt}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Other models to consider: \"gpt-3.5-turbo-0125\"\n",
    "    # Patch the OpenAI client with Instructor\n",
    "    client = instructor.from_openai(OpenAI(api_key=os.getenv('OPENAI_KEY')))\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name, \n",
    "        response_model=ExtractedInformation,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": extraction_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Use the given text to extract information: {text}\"},\n",
    "            {\"role\": \"user\", \"content\": \"\"\"\n",
    "                Here are the rules that you need to adhere:\n",
    "                ## Rules:\n",
    "                - The aim is to achieve simplicity and clarity in the extracted text.\n",
    "                - Make sure to answer in the structured format.\n",
    "                - If no information is provided for any of the fields, return nothing of that field.\n",
    "                - DO NOT HALLUCINATE.\n",
    "             \"\"\"},\n",
    "        ]\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_extraction_prompt = \"\"\"\n",
    "    Extract the following information from the text extracted from a webpage of a company:\n",
    "\n",
    "    1. Product Description:\n",
    "    - What service or product does the company provide?\n",
    "    - What features does the product or service have?\n",
    "    Note: If the company has more than one product or service, automatically detect and list each product with its relevant details.\n",
    "    \n",
    "    2. Summary of Product Offering:\n",
    "    - Summary of the description of the service that the company provide, taking into consideration of all the product offerings.\n",
    "    Note: Do not include any company-specific information in the summary, such as company name and location.\n",
    "    \n",
    "    3. Client Description:\n",
    "    - Name of the client or partner. Note: Only focus on corporate partners or clients, instead of individuals. \n",
    "    - Summary of the product or service used by the client or partner.\n",
    "    - Description of the use case.\n",
    "    Note: If the product used and description fields are not mentioned, they should be None.\n",
    "\n",
    "    Output in a structured format.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_extraction_execution(process_company_name:str):\n",
    "\n",
    "    summary_file_path = f'extraction_summary/{process_company_name}_summary_str.json'\n",
    "    if os.path.exists(summary_file_path):\n",
    "        with open(summary_file_path, 'r') as file:\n",
    "            summary = json.load(file)\n",
    "\n",
    "        combined_summary = f\"## Main Page:\\n {summary['main_page']}\\n----------------\\n\"\n",
    "\n",
    "        for endpoint, text in summary.items():\n",
    "            if endpoint != \"main_page\":\n",
    "                combined_summary += f\"## {endpoint}:\\n{text}\\n----------------\\n\"\n",
    "                \n",
    "        print(f'Cost: ${calculate_cost(combined_summary)}')\n",
    "        \n",
    "        # print(combined_summary)\n",
    "        \n",
    "        response = llm_information_extraction(combined_summary, product_extraction_prompt)\n",
    "        # print(response)\n",
    "        print(response.dict())\n",
    "        write_json_file(f'extraction_output_v2/{process_company_name}_extraction.json', response.dict())\n",
    "    else:\n",
    "        print(f'Summary file: {summary_file_path} does not exist.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'main_page'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mllm_extraction_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvesta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m, in \u001b[0;36mllm_extraction_execution\u001b[0;34m(process_company_name)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(summary_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      6\u001b[0m     summary \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m----> 8\u001b[0m combined_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Main Page:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43msummary\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmain_page\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m----------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m endpoint, text \u001b[38;5;129;01min\u001b[39;00m summary\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m endpoint \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_page\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'main_page'"
     ]
    }
   ],
   "source": [
    "llm_extraction_execution('vesta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_descriptions=[ProductDescription(name='Cloud Solutions', description='Scalability, security, and ease of use.')] product_offering_summary='Innovative cloud solutions that help businesses streamline their operations with key features including scalability, security, and ease of use.' client_descriptions=[ClientDescription(name='TechCorp', product_used='Cloud solutions', description='Improve data management, resulting in a 30% increase in efficiency.'), ClientDescription(name='SoftInc', product_used='Cloud solutions', description='Integrated services into their workflow, leading to significant improvements in project turnaround times.'), ClientDescription(name='Nationwide', product_used=None, description=None), ClientDescription(name='Freedom', product_used=None, description=None), ClientDescription(name='Bestow', product_used=None, description=None)]\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "text = \"\"\"\n",
    "Our company offers innovative cloud solutions that help businesses streamline their operations. Our key features include scalability, security, and ease of use.\n",
    "\n",
    "We partner with leading firms such as TechCorp and SoftInc to deliver top-notch services. For example, TechCorp uses our cloud solutions to improve their data management, resulting in a 30% increase in efficiency.\n",
    "\n",
    "Our client, SoftInc, has integrated our services into their workflow, leading to significant improvements in their project turnaround times.\n",
    "\n",
    "Our platform and service are trusted by these innovative companies:\n",
    "Clients are: Nationwide, Freedom, Bestow...\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "response = llm_information_extraction(text, product_extraction_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"product_descriptions\":[{\"name\":\"Cloud Solutions\",\"description\":\"Scalability, security, and ease of use.\"}],\"product_offering_summary\":\"Innovative cloud solutions that help businesses streamline their operations with key features including scalability, security, and ease of use.\",\"client_descriptions\":[{\"name\":\"TechCorp\",\"product_used\":\"Cloud solutions\",\"description\":\"Improve data management, resulting in a 30% increase in efficiency.\"},{\"name\":\"SoftInc\",\"product_used\":\"Cloud solutions\",\"description\":\"Integrated services into their workflow, leading to significant improvements in project turnaround times.\"},{\"name\":\"Nationwide\",\"product_used\":null,\"description\":null},{\"name\":\"Freedom\",\"product_used\":null,\"description\":null},{\"name\":\"Bestow\",\"product_used\":null,\"description\":null}]}'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
