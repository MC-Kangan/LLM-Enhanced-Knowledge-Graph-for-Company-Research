{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-28 11:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "from firecrawl_scraping import *\n",
    "from utility import *\n",
    "from llm_extraction import *\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import tiktoken as tiktoken\n",
    "import instructor\n",
    "from pydantic import BaseModel\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "import ast\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "current_dateTime = datetime.now(pytz.timezone('Etc/GMT'))\n",
    "print(current_dateTime.strftime(format = \"%Y-%m-%d %H:%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gpt-4o: \"o200k_base\",\n",
    "- gpt-4: \"cl100k_base\",\n",
    "- gpt-3.5-turbo: \"cl100k_base\",\n",
    "- gpt-3.5: \"cl100k_base\",  # Common shorthand\n",
    "- gpt-35-turbo : \"cl100k_base\",  # Azure deployment name\n",
    "\n",
    "gpt-4o US$5.00 / 1M input tokens； US$15.00 / 1M output tokens\n",
    "\n",
    "gpt-4o context length: 128K tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Encoding 'o200k_base'>\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>companies</th>\n",
       "      <th>company_former_name</th>\n",
       "      <th>company_legal_name</th>\n",
       "      <th>competitors</th>\n",
       "      <th>description</th>\n",
       "      <th>primary_industry_sector</th>\n",
       "      <th>primary_industry_group</th>\n",
       "      <th>primary_industry_code</th>\n",
       "      <th>all_industries</th>\n",
       "      <th>...</th>\n",
       "      <th>first_financing_valuation</th>\n",
       "      <th>first_financing_valuation_status</th>\n",
       "      <th>last_financing_valuation</th>\n",
       "      <th>last_financing_valuation_status</th>\n",
       "      <th>last_known_valuation</th>\n",
       "      <th>last_known_valuation_date</th>\n",
       "      <th>last_known_valuation_deal_type</th>\n",
       "      <th>processed_url</th>\n",
       "      <th>is_accessible</th>\n",
       "      <th>processed_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55185-04</td>\n",
       "      <td>Estimize</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Estimize, Inc.</td>\n",
       "      <td>Neudata, SigFig, Motif (Financial Software), Y...</td>\n",
       "      <td>Developer of an open financial estimates platf...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software</td>\n",
       "      <td>Financial Software</td>\n",
       "      <td>Financial Software*, Media and Information Ser...</td>\n",
       "      <td>...</td>\n",
       "      <td>6.34</td>\n",
       "      <td>Actual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.00</td>\n",
       "      <td>16/07/2015</td>\n",
       "      <td>Early Stage VC</td>\n",
       "      <td>www.estimize.com</td>\n",
       "      <td>True</td>\n",
       "      <td>estimize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56288-62</td>\n",
       "      <td>New Constructs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Constructs, LLC</td>\n",
       "      <td>Morningstar, CFRA, Finbox (Media and Informati...</td>\n",
       "      <td>Operator of an investment research firm intend...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software</td>\n",
       "      <td>Financial Software</td>\n",
       "      <td>Financial Software*, Media and Information Ser...</td>\n",
       "      <td>...</td>\n",
       "      <td>2.17</td>\n",
       "      <td>Actual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.17</td>\n",
       "      <td>13/05/2003</td>\n",
       "      <td>Early Stage VC</td>\n",
       "      <td>www.newconstructs.com</td>\n",
       "      <td>True</td>\n",
       "      <td>new_constructs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53739-01</td>\n",
       "      <td>Procore Technologies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Procore Technologies, Inc.</td>\n",
       "      <td>Projectmates, eBuilder, CMiC</td>\n",
       "      <td>Procore Technologies Inc is a cloud-based cons...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software</td>\n",
       "      <td>Business/Productivity Software</td>\n",
       "      <td>Business/Productivity Software*, Construction ...</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Actual</td>\n",
       "      <td>8585.03</td>\n",
       "      <td>Estimated</td>\n",
       "      <td>8585.03</td>\n",
       "      <td>20/05/2021</td>\n",
       "      <td>IPO</td>\n",
       "      <td>www.procore.com</td>\n",
       "      <td>True</td>\n",
       "      <td>procore_technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>153145-27</td>\n",
       "      <td>Proof</td>\n",
       "      <td>16 Pins, Notarize</td>\n",
       "      <td>Notarize, Inc.</td>\n",
       "      <td>Templafy, ZorroSign, eOriginal, PandaDoc, Cong...</td>\n",
       "      <td>Developer of an identity-assured transaction m...</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Software</td>\n",
       "      <td>Business/Productivity Software</td>\n",
       "      <td>Business/Productivity Software*, Media and Inf...</td>\n",
       "      <td>...</td>\n",
       "      <td>46.50</td>\n",
       "      <td>Actual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>760.00</td>\n",
       "      <td>25/03/2021</td>\n",
       "      <td>Later Stage VC</td>\n",
       "      <td>www.proof.com</td>\n",
       "      <td>True</td>\n",
       "      <td>proof</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52304-77</td>\n",
       "      <td>SMS Assist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SMS Assist, L.L.C.</td>\n",
       "      <td>ServiceChannel, Divisions Maintenance Group, T...</td>\n",
       "      <td>Provider of business services intended to deli...</td>\n",
       "      <td>Business Products and Services (B2B)</td>\n",
       "      <td>Commercial Services</td>\n",
       "      <td>Other Commercial Services</td>\n",
       "      <td>Buildings and Property, Business/Productivity ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>950.00</td>\n",
       "      <td>Estimated</td>\n",
       "      <td>950.00</td>\n",
       "      <td>05/01/2023</td>\n",
       "      <td>Merger/Acquisition</td>\n",
       "      <td>www.smsassist.com</td>\n",
       "      <td>True</td>\n",
       "      <td>sms_assist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_id             companies company_former_name  \\\n",
       "0   55185-04              Estimize                 NaN   \n",
       "1   56288-62        New Constructs                 NaN   \n",
       "3   53739-01  Procore Technologies                 NaN   \n",
       "5  153145-27                 Proof   16 Pins, Notarize   \n",
       "6   52304-77            SMS Assist                 NaN   \n",
       "\n",
       "           company_legal_name  \\\n",
       "0              Estimize, Inc.   \n",
       "1         New Constructs, LLC   \n",
       "3  Procore Technologies, Inc.   \n",
       "5              Notarize, Inc.   \n",
       "6          SMS Assist, L.L.C.   \n",
       "\n",
       "                                         competitors  \\\n",
       "0  Neudata, SigFig, Motif (Financial Software), Y...   \n",
       "1  Morningstar, CFRA, Finbox (Media and Informati...   \n",
       "3                       Projectmates, eBuilder, CMiC   \n",
       "5  Templafy, ZorroSign, eOriginal, PandaDoc, Cong...   \n",
       "6  ServiceChannel, Divisions Maintenance Group, T...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Developer of an open financial estimates platf...   \n",
       "1  Operator of an investment research firm intend...   \n",
       "3  Procore Technologies Inc is a cloud-based cons...   \n",
       "5  Developer of an identity-assured transaction m...   \n",
       "6  Provider of business services intended to deli...   \n",
       "\n",
       "                primary_industry_sector primary_industry_group  \\\n",
       "0                Information Technology               Software   \n",
       "1                Information Technology               Software   \n",
       "3                Information Technology               Software   \n",
       "5                Information Technology               Software   \n",
       "6  Business Products and Services (B2B)    Commercial Services   \n",
       "\n",
       "            primary_industry_code  \\\n",
       "0              Financial Software   \n",
       "1              Financial Software   \n",
       "3  Business/Productivity Software   \n",
       "5  Business/Productivity Software   \n",
       "6       Other Commercial Services   \n",
       "\n",
       "                                      all_industries  ...  \\\n",
       "0  Financial Software*, Media and Information Ser...  ...   \n",
       "1  Financial Software*, Media and Information Ser...  ...   \n",
       "3  Business/Productivity Software*, Construction ...  ...   \n",
       "5  Business/Productivity Software*, Media and Inf...  ...   \n",
       "6  Buildings and Property, Business/Productivity ...  ...   \n",
       "\n",
       "  first_financing_valuation first_financing_valuation_status  \\\n",
       "0                      6.34                           Actual   \n",
       "1                      2.17                           Actual   \n",
       "3                      4.00                           Actual   \n",
       "5                     46.50                           Actual   \n",
       "6                       NaN                              NaN   \n",
       "\n",
       "  last_financing_valuation  last_financing_valuation_status  \\\n",
       "0                      NaN                              NaN   \n",
       "1                      NaN                              NaN   \n",
       "3                  8585.03                        Estimated   \n",
       "5                      NaN                              NaN   \n",
       "6                   950.00                        Estimated   \n",
       "\n",
       "  last_known_valuation last_known_valuation_date  \\\n",
       "0                36.00                16/07/2015   \n",
       "1                 2.17                13/05/2003   \n",
       "3              8585.03                20/05/2021   \n",
       "5               760.00                25/03/2021   \n",
       "6               950.00                05/01/2023   \n",
       "\n",
       "  last_known_valuation_deal_type          processed_url  is_accessible  \\\n",
       "0                 Early Stage VC       www.estimize.com           True   \n",
       "1                 Early Stage VC  www.newconstructs.com           True   \n",
       "3                            IPO        www.procore.com           True   \n",
       "5                 Later Stage VC          www.proof.com           True   \n",
       "6             Merger/Acquisition      www.smsassist.com           True   \n",
       "\n",
       "         processed_name  \n",
       "0              estimize  \n",
       "1        new_constructs  \n",
       "3  procore_technologies  \n",
       "5                 proof  \n",
       "6            sms_assist  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv('data/PitchBook_All_Columns_2024_07_04_14_48_36_accessibility.csv')\n",
    "df_all = df_all[~df_all['business_status'].isin(['Out of Business', 'Bankruptcy: Liquidation', 'Bankruptcy: Admin/Reorg'])]\n",
    "df_all['companies'] = df_all['companies'].str.replace(r'\\s*\\(.*?\\)\\s*', '', regex=True)\n",
    "df_all = df_all[df_all['is_accessible'] == True]\n",
    "df_all['processed_name'] = df_all['companies'].apply(process_company_name)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_additional_info(processed_name:str, column_name:str):\n",
    "    df_all = pd.read_csv('data/PitchBook_All_Columns_2024_07_04_14_48_36_accessibility.csv')\n",
    "    df_all['companies'] = df_all['companies'].str.replace(r'\\s*\\(.*?\\)\\s*', '', regex=True)\n",
    "    df_all['processed_name'] = df_all['companies'].apply(process_company_name)\n",
    "    \n",
    "    df_select = df_all[df_all['processed_name'] == processed_name]\n",
    "    if len(df_select) > 0:\n",
    "        return df_select[column_name].iloc[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('companies_urls_info.csv')\n",
    "sample = df[~df['url'].isin(['https://www.vertice.one', \n",
    "                    'https://www.estimize.com',\n",
    "                    'https://www.newconstructs.com',\n",
    "                    'https://www.chargebee.com',\n",
    "                    'https://www.bennie.com',\n",
    "                    'https://www.aercompliance.com',\n",
    "                    'https://www.missionmark.com',\n",
    "                    'https://www.joinmassive.com',\n",
    "                    'https://www.hemlane.com',\n",
    "                    'https://www.vesta.com',\n",
    "                    'https://www.adaptive.build',\n",
    "                    'https://www.additive.ai',\n",
    "                    'https://www.9fin.com',\n",
    "                    'https://www.niloom.ai',\n",
    "                    'https://www.nexben.com',\n",
    "                    'https://www.naturealpha.ai',\n",
    "                    'https://www.lworks.io',\n",
    "                    'https://www.infogrid.io',\n",
    "                    'https://www.harnessproperty.com',\n",
    "                    'https://www.directsoftware.com',\n",
    "                    'https://www.dexitcorp.com',\n",
    "                    'https://www.bankerslab.com',\n",
    "                    'https://www.avyst.com',\n",
    "                    'https://www.aggregion.com',\n",
    "                    'https://www.validifi.com',\n",
    "                    'https://www.revvin.com',\n",
    "                    'https://www.gotyou.co',\n",
    "                    'https://www.credenza3.com',\n",
    "                    'https://www.concertocard.com',\n",
    "                    'https://www.element.io',\n",
    "                    'https://www.deepview.com',\n",
    "                    'https://www.realgrader.com',\n",
    "                    'https://www.fanpage.com',\n",
    "                    'https://www.insurgrid.com',\n",
    "                    'https://www.cobalt.pe',\n",
    "                    'https://www.soundout.com',\n",
    "                    'https://www.imoto.com',\n",
    "                    'https://www.ontheupper.com',\n",
    "                    'https://www.getzorba.com',\n",
    "                    'https://www.paralian.io',\n",
    "                    'https://www.gzi.finance',\n",
    "                    'https://www.retailmarketpoint.com',\n",
    "                    'https://www.yardikube.com',\n",
    "                    'https://www.getwats.com',\n",
    "                    'https://www.truelytics.com',\n",
    "                    'https://www.trykintsugi.com',\n",
    "                    'https://www.veruna.com',\n",
    "                    'https://www.tailpath.com',\n",
    "                    'https://www.worksmith.com',\n",
    "                    'https://www.go-maestro.com',\n",
    "                    'https://www.goblueswipe.com',\n",
    "                    'https://www.useink.com',\n",
    "                    'https://www.verdata.com',\n",
    "                    'https://www.beauhurst.com',\n",
    "                    'https://www.saltmine.com',\n",
    "                    'https://www.nammu21.com',\n",
    "                    'https://www.alaffiahealth.com',\n",
    "                    'https://www.bookingpal.com',\n",
    "                    'https://www.metrika.co',\n",
    "                    'https://www.accumula.com',\n",
    "                    'https://www.flowfi.com',\n",
    "                    'https://www.prodeal360.com',\n",
    "                    'https://www.krowdit.com',\n",
    "                    'https://www.jibtechnologies.com',\n",
    "                    'https://www.fieldwire.com',\n",
    "                    'https://www.commercesync.com',\n",
    "                    'https://www.arcana.io',\n",
    "                    'https://www.copernicspace.com',\n",
    "                    'https://www.youattest.com',\n",
    "                    'https://www.pilotbird.com',\n",
    "                    'https://www.pocketbook.tech',\n",
    "                    'https://www.chainlinklabs.com',\n",
    "                    'https://www.proper.ai',\n",
    "                    'https://www.layer.team',\n",
    "                    'https://www.veriphyanalytics.com',\n",
    "                    'https://www.wearegroov.io',\n",
    "                    'https://www.buildstock.com',\n",
    "                    'https://www.scriptainsights.com',\n",
    "                    'https://www.solisolutions.net',\n",
    "                    'https://www.titanpay.ai',\n",
    "                    'https://www.herondata.io',\n",
    "                    'https://www.locatestrategy.com',\n",
    "                    'https://www.hopemacy.com',\n",
    "                    'https://www.smartpayllc.com',\n",
    "                    'https://www.prospectnow.com',\n",
    "                    'https://www.hashku.com',\n",
    "                    'https://www.prismdata.com',\n",
    "                    'https://www.taxometry.com',\n",
    "                    'https://www.r3vl.xyz',\n",
    "                    'https://www.avantarisk.com',\n",
    "                    'https://www.every.io',\n",
    "                    'https://www.joot.io',\n",
    "                    'https://www.buildops.com',\n",
    "                    'https://www.downtobid.com',\n",
    "                    'https://www.plural.ai',\n",
    "                    'https://www.bitwage.com',\n",
    "                    'https://www.gorodeo.app',\n",
    "                    'https://www.ledgible.io',\n",
    "                    'https://www.artd.ai',\n",
    "                    'https://www.acumatica.com',\n",
    "                    'https://www.carby.cc',\n",
    "                    'https://www.shibuya.film',\n",
    "                    'https://www.trelora.com',\n",
    "                    'https://www.regeo.co',\n",
    "                    'https://www.sustainround.com',\n",
    "                    'https://www.cherre.com',\n",
    "                    'https://www.yottled.com',\n",
    "                    'https://www.singularities.com',\n",
    "                    'https://www.domoticsre.com',\n",
    "                    'https://www.dexfreight.io',\n",
    "                    'https://www.nue.io',\n",
    "                    'https://www.atto.co '\n",
    "                    ])]\n",
    "\n",
    "sample = sample.iloc[:180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>processed_name</th>\n",
       "      <th>url</th>\n",
       "      <th>related_urls_str</th>\n",
       "      <th>related_urls</th>\n",
       "      <th>num_of_related_urls</th>\n",
       "      <th>all_urls</th>\n",
       "      <th>num_of_all_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Solidspac3</td>\n",
       "      <td>solidspac3</td>\n",
       "      <td>https://www.solidspac3.com</td>\n",
       "      <td>https://www.solidspac3.com</td>\n",
       "      <td>['https://www.solidspac3.com']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.solidspac3.com', 'https://www.so...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Gravity Software</td>\n",
       "      <td>gravity_software</td>\n",
       "      <td>https://www.gogravity.com</td>\n",
       "      <td>https://www.gogravity.com/product/functionalit...</td>\n",
       "      <td>['https://www.gogravity.com/product/functional...</td>\n",
       "      <td>44</td>\n",
       "      <td>['https://www.gogravity.com/industries/investm...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>IPGen</td>\n",
       "      <td>ipgen</td>\n",
       "      <td>https://www.ipgen.io</td>\n",
       "      <td>https://www.ipgen.io</td>\n",
       "      <td>['https://www.ipgen.io']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.ipgen.io/law-firms/', 'https://w...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>The Booking Factory</td>\n",
       "      <td>the_booking_factory</td>\n",
       "      <td>https://www.thebookingfactory.com</td>\n",
       "      <td>https://www.thebookingfactory.com/services#par...</td>\n",
       "      <td>['https://www.thebookingfactory.com/services#p...</td>\n",
       "      <td>10</td>\n",
       "      <td>['https://www.thebookingfactory.com/white-labe...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Combat IQ</td>\n",
       "      <td>combat_iq</td>\n",
       "      <td>https://www.combatiq.io</td>\n",
       "      <td>https://www.combatiq.io</td>\n",
       "      <td>['https://www.combatiq.io']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.combatiq.io/schedule-demo', 'htt...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Anybill</td>\n",
       "      <td>anybill</td>\n",
       "      <td>https://www.anybill.com</td>\n",
       "      <td>https://www.anybill.com/services,https://www.a...</td>\n",
       "      <td>['https://www.anybill.com/services', 'https://...</td>\n",
       "      <td>4</td>\n",
       "      <td>['https://www.anybill.com/careers', 'https://w...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Caligotech</td>\n",
       "      <td>caligotech</td>\n",
       "      <td>https://www.caligotech.com</td>\n",
       "      <td>https://www.caligotech.com</td>\n",
       "      <td>['https://www.caligotech.com']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.caligotech.com/careers', 'https:...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>iLumen</td>\n",
       "      <td>ilumen</td>\n",
       "      <td>https://www.ilumen.com</td>\n",
       "      <td>https://www.ilumen.com/case-studies,https://ww...</td>\n",
       "      <td>['https://www.ilumen.com/case-studies', 'https...</td>\n",
       "      <td>5</td>\n",
       "      <td>['https://www.ilumen.com/case-studies', 'https...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>iknowa</td>\n",
       "      <td>iknowa</td>\n",
       "      <td>https://www.iknowa.com</td>\n",
       "      <td>https://www.iknowa.com</td>\n",
       "      <td>['https://www.iknowa.com']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.iknowa.com/', 'https://www.iknow...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Loanbase</td>\n",
       "      <td>loanbase</td>\n",
       "      <td>https://www.loanbase.com</td>\n",
       "      <td>https://www.loanbase.com/case-studies/,https:/...</td>\n",
       "      <td>['https://www.loanbase.com/case-studies/', 'ht...</td>\n",
       "      <td>2</td>\n",
       "      <td>['https://www.loanbase.com#brokers', 'https://...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 company       processed_name  \\\n",
       "269           Solidspac3           solidspac3   \n",
       "270     Gravity Software     gravity_software   \n",
       "271                IPGen                ipgen   \n",
       "272  The Booking Factory  the_booking_factory   \n",
       "273            Combat IQ            combat_iq   \n",
       "274              Anybill              anybill   \n",
       "275           Caligotech           caligotech   \n",
       "276               iLumen               ilumen   \n",
       "277               iknowa               iknowa   \n",
       "278             Loanbase             loanbase   \n",
       "\n",
       "                                   url  \\\n",
       "269         https://www.solidspac3.com   \n",
       "270          https://www.gogravity.com   \n",
       "271               https://www.ipgen.io   \n",
       "272  https://www.thebookingfactory.com   \n",
       "273            https://www.combatiq.io   \n",
       "274            https://www.anybill.com   \n",
       "275         https://www.caligotech.com   \n",
       "276             https://www.ilumen.com   \n",
       "277             https://www.iknowa.com   \n",
       "278           https://www.loanbase.com   \n",
       "\n",
       "                                      related_urls_str  \\\n",
       "269                         https://www.solidspac3.com   \n",
       "270  https://www.gogravity.com/product/functionalit...   \n",
       "271                               https://www.ipgen.io   \n",
       "272  https://www.thebookingfactory.com/services#par...   \n",
       "273                            https://www.combatiq.io   \n",
       "274  https://www.anybill.com/services,https://www.a...   \n",
       "275                         https://www.caligotech.com   \n",
       "276  https://www.ilumen.com/case-studies,https://ww...   \n",
       "277                             https://www.iknowa.com   \n",
       "278  https://www.loanbase.com/case-studies/,https:/...   \n",
       "\n",
       "                                          related_urls  num_of_related_urls  \\\n",
       "269                     ['https://www.solidspac3.com']                    1   \n",
       "270  ['https://www.gogravity.com/product/functional...                   44   \n",
       "271                           ['https://www.ipgen.io']                    1   \n",
       "272  ['https://www.thebookingfactory.com/services#p...                   10   \n",
       "273                        ['https://www.combatiq.io']                    1   \n",
       "274  ['https://www.anybill.com/services', 'https://...                    4   \n",
       "275                     ['https://www.caligotech.com']                    1   \n",
       "276  ['https://www.ilumen.com/case-studies', 'https...                    5   \n",
       "277                         ['https://www.iknowa.com']                    1   \n",
       "278  ['https://www.loanbase.com/case-studies/', 'ht...                    2   \n",
       "\n",
       "                                              all_urls  num_of_all_urls  \n",
       "269  ['https://www.solidspac3.com', 'https://www.so...                2  \n",
       "270  ['https://www.gogravity.com/industries/investm...               77  \n",
       "271  ['https://www.ipgen.io/law-firms/', 'https://w...               18  \n",
       "272  ['https://www.thebookingfactory.com/white-labe...               32  \n",
       "273  ['https://www.combatiq.io/schedule-demo', 'htt...                7  \n",
       "274  ['https://www.anybill.com/careers', 'https://w...               12  \n",
       "275  ['https://www.caligotech.com/careers', 'https:...                9  \n",
       "276  ['https://www.ilumen.com/case-studies', 'https...               19  \n",
       "277  ['https://www.iknowa.com/', 'https://www.iknow...                2  \n",
       "278  ['https://www.loanbase.com#brokers', 'https://...               16  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>processed_name</th>\n",
       "      <th>url</th>\n",
       "      <th>related_urls_str</th>\n",
       "      <th>related_urls</th>\n",
       "      <th>num_of_related_urls</th>\n",
       "      <th>all_urls</th>\n",
       "      <th>num_of_all_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Rental Beast</td>\n",
       "      <td>rental_beast</td>\n",
       "      <td>https://www.rentalbeast.com</td>\n",
       "      <td>https://www.rentalbeast.com</td>\n",
       "      <td>['https://www.rentalbeast.com']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.rentalbeast.com/about-rental-bea...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Nophin</td>\n",
       "      <td>nophin</td>\n",
       "      <td>https://www.nophin.com</td>\n",
       "      <td>https://www.nophin.com</td>\n",
       "      <td>['https://www.nophin.com']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.nophin.com/terms-of-use', 'https...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Candidly</td>\n",
       "      <td>candidly</td>\n",
       "      <td>https://www.getcandidly.com</td>\n",
       "      <td>https://www.getcandidly.com</td>\n",
       "      <td>['https://www.getcandidly.com']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.getcandidly.com', 'https://www.g...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Mango REIX</td>\n",
       "      <td>mango_reix</td>\n",
       "      <td>https://www.mangoreix.com</td>\n",
       "      <td>https://www.mangoreix.com</td>\n",
       "      <td>['https://www.mangoreix.com']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.mangoreix.com/_files/ugd/b3a289_...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Next Quarter</td>\n",
       "      <td>next_quarter</td>\n",
       "      <td>https://www.nextq.ai</td>\n",
       "      <td>https://www.nextq.ai</td>\n",
       "      <td>['https://www.nextq.ai']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.nextq.ai', 'https://www.nextq.ai...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Howsy</td>\n",
       "      <td>howsy</td>\n",
       "      <td>https://www.howsy.com</td>\n",
       "      <td>https://www.howsy.com</td>\n",
       "      <td>['https://www.howsy.com']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.howsy.com']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Terrene Labs</td>\n",
       "      <td>terrene_labs</td>\n",
       "      <td>https://www.terrenelabs.com</td>\n",
       "      <td>https://www.terrenelabs.com</td>\n",
       "      <td>['https://www.terrenelabs.com']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.terrenelabs.com']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>AuthorLoyalty</td>\n",
       "      <td>authorloyalty</td>\n",
       "      <td>https://www.authorloyalty.com</td>\n",
       "      <td>https://www.authorloyalty.com</td>\n",
       "      <td>['https://www.authorloyalty.com']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.authorloyalty.com']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Solidspac3</td>\n",
       "      <td>solidspac3</td>\n",
       "      <td>https://www.solidspac3.com</td>\n",
       "      <td>https://www.solidspac3.com</td>\n",
       "      <td>['https://www.solidspac3.com']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.solidspac3.com', 'https://www.so...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>IPGen</td>\n",
       "      <td>ipgen</td>\n",
       "      <td>https://www.ipgen.io</td>\n",
       "      <td>https://www.ipgen.io</td>\n",
       "      <td>['https://www.ipgen.io']</td>\n",
       "      <td>1</td>\n",
       "      <td>['https://www.ipgen.io/law-firms/', 'https://w...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           company processed_name                            url  \\\n",
       "91    Rental Beast   rental_beast    https://www.rentalbeast.com   \n",
       "92          Nophin         nophin         https://www.nophin.com   \n",
       "93        Candidly       candidly    https://www.getcandidly.com   \n",
       "96      Mango REIX     mango_reix      https://www.mangoreix.com   \n",
       "98    Next Quarter   next_quarter           https://www.nextq.ai   \n",
       "..             ...            ...                            ...   \n",
       "256          Howsy          howsy          https://www.howsy.com   \n",
       "258   Terrene Labs   terrene_labs    https://www.terrenelabs.com   \n",
       "262  AuthorLoyalty  authorloyalty  https://www.authorloyalty.com   \n",
       "269     Solidspac3     solidspac3     https://www.solidspac3.com   \n",
       "271          IPGen          ipgen           https://www.ipgen.io   \n",
       "\n",
       "                  related_urls_str                       related_urls  \\\n",
       "91     https://www.rentalbeast.com    ['https://www.rentalbeast.com']   \n",
       "92          https://www.nophin.com         ['https://www.nophin.com']   \n",
       "93     https://www.getcandidly.com    ['https://www.getcandidly.com']   \n",
       "96       https://www.mangoreix.com      ['https://www.mangoreix.com']   \n",
       "98            https://www.nextq.ai           ['https://www.nextq.ai']   \n",
       "..                             ...                                ...   \n",
       "256          https://www.howsy.com          ['https://www.howsy.com']   \n",
       "258    https://www.terrenelabs.com    ['https://www.terrenelabs.com']   \n",
       "262  https://www.authorloyalty.com  ['https://www.authorloyalty.com']   \n",
       "269     https://www.solidspac3.com     ['https://www.solidspac3.com']   \n",
       "271           https://www.ipgen.io           ['https://www.ipgen.io']   \n",
       "\n",
       "     num_of_related_urls                                           all_urls  \\\n",
       "91                     1  ['https://www.rentalbeast.com/about-rental-bea...   \n",
       "92                     1  ['https://www.nophin.com/terms-of-use', 'https...   \n",
       "93                     1  ['https://www.getcandidly.com', 'https://www.g...   \n",
       "96                     1  ['https://www.mangoreix.com/_files/ugd/b3a289_...   \n",
       "98                     1  ['https://www.nextq.ai', 'https://www.nextq.ai...   \n",
       "..                   ...                                                ...   \n",
       "256                    1                          ['https://www.howsy.com']   \n",
       "258                    1                    ['https://www.terrenelabs.com']   \n",
       "262                    1                  ['https://www.authorloyalty.com']   \n",
       "269                    1  ['https://www.solidspac3.com', 'https://www.so...   \n",
       "271                    1  ['https://www.ipgen.io/law-firms/', 'https://w...   \n",
       "\n",
       "     num_of_all_urls  \n",
       "91                25  \n",
       "92                 4  \n",
       "93                 2  \n",
       "96                 3  \n",
       "98                 5  \n",
       "..               ...  \n",
       "256                1  \n",
       "258                1  \n",
       "262                1  \n",
       "269                2  \n",
       "271               18  \n",
       "\n",
       "[87 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[sample['num_of_related_urls']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurs on .DS_Store: 'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n"
     ]
    }
   ],
   "source": [
    "doc_list = os.listdir('scraping_output_v2_raw')\n",
    "for doc in doc_list:\n",
    "    \n",
    "    try: \n",
    "        data = read_json_file(f'scraping_output_v2_raw/{doc}')\n",
    "        if 'timestamp' not in data:\n",
    "            current_dateTime = datetime.now(pytz.timezone('Etc/GMT'))\n",
    "            data['timestamp'] = current_dateTime.strftime(format = \"%Y-%m-%d %H:%M\")\n",
    "            \n",
    "        if \"processed_company\" not in data:\n",
    "            process_name = doc.replace('.json', '')\n",
    "            data[\"processed_company\"] = process_name\n",
    "            \n",
    "        if \"url\" not in data:\n",
    "            data[\"url\"] = \"https://\" + get_additional_info(process_name, 'processed_url')\n",
    "        \n",
    "        write_json_file(f'scraping_output_v2_raw/{doc}', data)\n",
    "    except Exception as e:\n",
    "        print(f'Error occurs on {doc}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(sample.iterrows(), total=len(sample), desc=\"Scraping data\", position=0, leave=True):\n",
    "    base_url = row['url']\n",
    "    url_list = ast.literal_eval(row['related_urls'])\n",
    "    result = crawl_data(base_url, url_list, f'scraping_output_v2_raw/{row[\"processed_name\"]}.json', overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Talk to a human: [(866) 387-1629]\n",
      "[Sign in]\n",
      "REALTORS®' Partner in Property Management\n",
      "**The best agents** help their clients get the most out of their rental properties.\n",
      "![Voted Capterra's Top 20 Property Management Solutions]![Software Advice most recommended Property Management Solution badge]![Software Advice Real Estate Property Management Front Runner Badge]![Software Advice Badge - Best Customer Support for Property Management]![GetApp Badge - Best Functionality and Features]\n",
      "Back\n",
      "How do you support your clients with their rental properties?\n",
      "I want to refer landlords\n",
      "(and get paid for it)\n",
      "I offer leasing\n",
      "(and want free leads and tools)\n",
      "I offer property management\n",
      "(and want to eliminate trust accounts)\n",
      "Check out other REALTORS® partnering with us\n",
      "![]![Headshot of Timothy Hampson]\n",
      "Timothy Hampson\n",
      "License #9008072 (TX)\n",
      "HP2 RESIDENTIAL\n",
      "Experience\n",
      "Leasing\n",
      "12 years\n",
      "Management\n",
      "Real estate\n",
      "![]![Headshot of Sandy Wickware]\n",
      "Sandy Wickware\n",
      "License #253554 (TX)\n",
      "Fathom Realty, LLC\n",
      "14 years\n",
      "2 years\n",
      "![]![Headshot of Kadee McGwier]\n",
      "Kadee McGwier\n",
      "License #SP43079 (ID), #135248 (WA), #RRE-RBS-LIC-98863 (MT)\n",
      "B Wright At Home LLC\n",
      "5 years\n",
      "7 years\n",
      "...and many more.\n",
      "Not ready to try any of these today but want us to market your services for free?\n",
      "[Create your free agent profile]\n"
     ]
    }
   ],
   "source": [
    "data = read_json_file('scraping_output_v2_raw/hemlane.json')\n",
    "\n",
    "print(clean_scraped_content(data['/realtor-partners/']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/realtor-partners/\n",
      "Estimated GPT4-o cost: $0.08219499999999999\n",
      "Estimated GPT4-o cost after cleaning: $0.00167\n",
      "------------------------\n",
      "main_page\n",
      "Estimated GPT4-o cost: $0.01288\n",
      "Estimated GPT4-o cost after cleaning: $0.005535\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for url, content in data.items():\n",
    "    print(url)\n",
    "    print(f'Estimated GPT4-o cost: ${calculate_cost(data[url])}')\n",
    "    print(f'Estimated GPT4-o cost after cleaning: ${calculate_cost(clean_scraped_content(data[url]))}')\n",
    "    print('------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of first shorten the page by extracting relevant information\n",
    "Issue: The output of the content might be shorten too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def llm_summary(text, model_name=\"gpt-4o\"):\n",
    "    system_message = \"\"\"\n",
    "    You are an intelligent text extraction and conversion assistant. Your task is to extract information \n",
    "    from the given text and convert it into a text (string) format. \n",
    "    The output response should contain only the data extracted from the text, with no additional commentary, explanations, or extraneous information.\n",
    "    If the required information could not be found from the given source, return nothing. Do not hallucinate.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the extraction prompt\n",
    "    extraction_prompt = \"\"\"\n",
    "    You are provided with a text obtained from a company's webpage. Your task is to extract any sections or paragraphs that are relevant to the specified information of interest.\n",
    "\n",
    "    ## Information of Interest:\n",
    "\n",
    "    1. **About Product or Service**:\n",
    "    - Any details about the products or services the company offers, including their features.\n",
    "\n",
    "    2. **About Partner or Client**:\n",
    "    - Any information about the company's partners or clients.\n",
    "    - Any use cases (case studies) describing how a client is using the company's product or service.\n",
    "    \n",
    "    ## Note:\n",
    "    Sometimes, the company does not explicit describe their clients and the client use case, instead, they will only display clients' logos. \n",
    "    You then need to extract client's name from their logos. \n",
    "    \n",
    "    ## Instructions:\n",
    "    - Do not summarize the content. Extract the raw lines or sections as they are.\n",
    "    - If you are unsure about the relevance of the information, include it to ensure comprehensive coverage.\n",
    "    - Output the extracted information in standard text format.\n",
    "\n",
    "    ## Examples:\n",
    "\n",
    "    ### Example 1: Product or Service\n",
    "    If the input text contains:\n",
    "    \"Our company offers innovative cloud solutions that help businesses streamline their operations. Our key features include scalability, security, and ease of use.\n",
    "    We partner with leading firms such as TechCorp and SoftInc to deliver top-notch services.\"\n",
    "\n",
    "    The output should be:\n",
    "    \"Our company offers innovative cloud solutions that help businesses streamline their operations. Our key features include scalability, security, and ease of use.\n",
    "    We partner with leading firms such as TechCorp and SoftInc to deliver top-notch services.\"\n",
    "\n",
    "    ### Example 2: Client Logos\n",
    "    If the input text contains:\n",
    "    \"Our platform and service is trusted by these innovative companies:\n",
    "    ![Nationwide Logo]\n",
    "    ![Freedom 365 Logo]\n",
    "    ![Bestow Logo]\n",
    "    ...\"\n",
    "    \n",
    "    The output should be:\n",
    "    \"Our platform and service is trusted by these innovative companies: \n",
    "    Clients are: Nationwide, Freedom 365, Bestow...\"\n",
    "   \n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_message),\n",
    "            (\"system\", extraction_prompt),\n",
    "            (\"human\", \"Use the given text to extract information: {input}\"),\n",
    "            (\"human\", \"\"\"\n",
    "                Here are the rules that you need to adhere:\n",
    "                ## Rules:\n",
    "                - Make sure to answer in the standard text format.\n",
    "                - If no information is provided, return nothing.\n",
    "                - DO NOT HALLUCINATE.\n",
    "             \"\"\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    llm = ChatOpenAI(openai_api_key=os.getenv('OPENAI_KEY'),\n",
    "                    temperature=0, \n",
    "                    model_name=model_name)\n",
    "\n",
    "    llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    response = llm_chain.invoke({'input': text})\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "def llm_summary_execution(processed_name:str, overwrite:bool = False, model_name:str = 'gpt-4o-mini'):\n",
    "\n",
    "    scrape_file_path = f'scraping_output_v2_raw/{processed_name}.json'\n",
    "    extraction_file_path = f'extraction_summary_v2/{processed_name}_summary_str.json'\n",
    "\n",
    "    scrape_data = read_json_file(scrape_file_path)\n",
    "    \n",
    "    file_modified = False\n",
    "\n",
    "    # Load existing data if the file exists\n",
    "    if os.path.exists(extraction_file_path):\n",
    "        with open(extraction_file_path, 'r') as file:\n",
    "            extracted_data = json.load(file)\n",
    "    else:\n",
    "        extracted_data = {}\n",
    "\n",
    "    for endpoint, content in tqdm(scrape_data.items(), total=len(scrape_data), desc=\"Extracting data\", position=0, leave=True):\n",
    "        if endpoint in ['timestamp', 'processed_company', 'url']:\n",
    "            continue\n",
    "        if endpoint in extracted_data and not overwrite:\n",
    "            print(f\"Company: {processed_name}; Skipping {endpoint} as it already exists and overwrite is set to False.\")\n",
    "            continue  # Skip this URL and move to the next one\n",
    "        else:\n",
    "            clean_content = clean_scraped_content(content)\n",
    "            extracted_data[endpoint] = llm_summary(text = clean_content, model_name = model_name)\n",
    "            print(f'Company: {processed_name}; Content in {endpoint} is extracted.')\n",
    "            \n",
    "            current_dateTime = datetime.now(pytz.timezone('Etc/GMT'))\n",
    "            extracted_data['timestamp'] = current_dateTime.strftime(format = \"%Y-%m-%d %H:%M\") + ' Etc/GMT'\n",
    "            file_modified = True\n",
    "    \n",
    "    if file_modified:\n",
    "        extracted_data['processed_company'] = processed_name\n",
    "        extracted_data['url'] = \"https://\" + get_additional_info(processed_name, 'processed_url')\n",
    "        write_json_file(extraction_file_path, extracted_data)\n",
    "        \n",
    "    return extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = os.listdir('extraction_summary')\n",
    "for doc in doc_list:\n",
    "    processed_name = doc.replace('_summary_str.json', '')\n",
    "    response = llm_summary_execution(processed_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Explore Vendors]\n",
      "[Contact]\n",
      "[Log In]\n",
      "[Start Saving]\n",
      "Unified SaaS Purchasing\n",
      "Purchasing, renewing and streamlining your SaaS stack just became a whole lot easier\n",
      "[Watch the video]\n",
      "![Contracts List Panel]\n",
      "![Existing Contract Button]\n",
      "![Search Applications Field]\n",
      "![All Departments Field]\n",
      "![SaaS Renewals Pipeline]\n",
      "![Autocad Fusion Card]\n",
      "![Total Contracts Card]\n",
      "![In Progress Card]\n",
      "![Awaiting Approval Card]\n",
      "![Empty Dashboard Background]\n",
      "Trusted by Finance and Procurement Leaders\n",
      "[![MotorK Logo]](#)\n",
      "[![Ebury Logo]](#)\n",
      "[![ba&sh Logo]](#)\n",
      "[![Lincoln Investment Logo]](#)\n",
      "[![Wallbox Logo]](#)\n",
      "[![Matillion Logo]](#)\n",
      "[![PageUp Logo]](#)\n",
      "[![Omio Logo]](#)\n",
      "[![Coronado Logo]](#)\n",
      "[![Revel Logo]](#)\n",
      "[![Podimo Logo]](#)\n",
      "[![Haiilo Logo]](#)\n",
      "[![Le Collectionist Logo]](#)\n",
      "[![Euronext Logo]](#)\n",
      "[![Choco Logo]](#)\n",
      "[![Futureverse Logo]](#)\n",
      "[![Multiplica Logo]](#)\n",
      "Benefits  \n",
      "Your SaaS purchasing has never been so under control\n",
      "Every corner of our product is designed to help you understand your SaaS stack better\n",
      "[### Full Stack Visibility\\\n",
      "Proactively keep track of your software renewals, requests, and tail spend.\\\n",
      "SaaS Visibility](/platform/saas-purchasing/saas-visibility)\n",
      "[### Usage and Analytics\\\n",
      "Track your license usage, helping you spot overspend and tool under-utilization.\\\n",
      "Analytics and Benchmarking](/platform/saas-purchasing/usage-analytics-discovery)\n",
      "[### Vendor Benchmarking\\\n",
      "Data on 16,000+ vendors, showing you the real price you ought to be paying.\\\n",
      "Browse Vendors](/vendors)\n",
      "### Expert Buyers\\\n",
      "Our specialists partner with you to secure you the best possible deal, typically achieving savings of 20-30%.](/platform/saas-purchasing/expert-buying-benchmarking)\n",
      "The Proof  \n",
      "Lose the pounds. Cut the sprawl.\n",
      "Our tech-enabled service and unrivalled experience combine to give you the best possible time and money savings\n",
      "2BN\n",
      "Managed Spend\n",
      "Across every industry and 98 countries\n",
      "4500+\n",
      "Contracts Negotiated\n",
      "Unparalled experience\n",
      "280Hrs+\n",
      "AVG saved per year\n",
      "Don't just save money\n",
      "[Features]\n",
      "Get full control over your SaaS\n",
      "You will have never seen your SaaS stack in so much detail, or had so many opportunities to cut costs\n",
      "Visibility\n",
      "Expert Buying\n",
      "Analytics\n",
      "Benchmarking\n",
      "### Full visibility into your SaaS stack\n",
      "Get a complete view of your software spend, renewal timelines and compliance info in one simple dashboard.\n",
      "![SaaS Purchasing Dashboard]\n",
      "### Partner with us\n",
      "Equipped with an intimate knowledge of every vendor’s sales process, our highly-experienced expert buying team works alongside yours to negotiate fairer prices and better terms.\n",
      "![SaaS Renewal Card View]\n",
      "### See the truth of your usage\n",
      "Through integrations, we show you your software utilization - and any wastage - throughout your entire stack.\n",
      "![SaaS Usage Analytics Dashboard]\n",
      "### Leverage Our Vendor Benchmarks\n",
      "We maintain a live database of 16,000+ vendors' pricing and terms, so we can help you pay only what you should.\n",
      "![SaaS Vendors Marketplace]\n",
      "[Customer Stories]\n",
      "Don’t take it from us. Hear it from them.\n",
      "The visionary startups and industry leaders who use us to optimize their spend\n",
      "![Crunch Logo]\n",
      "![Holded Logo]\n",
      "![Lighthouse Logo]\n",
      "![A.Team Logo]\n",
      "![Crunch]\\\n",
      "Over $100k saved in only 3 months\\\n",
      "“Aside from the money savings, the time saving element has also taken a lot off my plate and other people’s plates.”\\\n",
      "![Helena Straussman]\\\n",
      "Helena Straussman\\\n",
      "Operations and Transformation Director\\\n",
      "at\\\n",
      "Crunch](/customer-stories/crunch)\n",
      "![Holded]\\\n",
      "Onboarded in 10 days and average 20% SaaS savings\\\n",
      "“We’ve been amazed at the savings we have been able to generate with Vertice. It was absolutely the right decision to work with them.”\\\n",
      "![Sam Maldonado]\\\n",
      "Sam Maldonado\\\n",
      "VP of Finance\\\n",
      "Holded](/customer-stories/holded)\n",
      "![Lighthouse]\\\n",
      "$170,000 saved on a single SaaS contract\\\n",
      "“Vertice has been a great partner from the start by bringing amazing instant ROI and reducing the time spent negotiating contracts.”\\\n",
      "![Matthias Geeroms]\\\n",
      "Matthias Geeroms\\\n",
      "Co-founder & CFO\\\n",
      "Lighthouse](/customer-stories/lighthouse)\n",
      "![A.Team]\\\n",
      "$330k savings in first three months and a 7x ROI overall\\\n",
      "“I've been able to ditch my spreadsheet of contracts and licenses now that everything is cleanly available with Vertice. I'm also saving a lot of time so it's a win all around.”\\\n",
      "![Christopher Gonzalez]\\\n",
      "Christopher Gonzalez\\\n",
      "Head of Finance\\\n",
      "A.Team](/customer-stories/ateam)\n",
      "[Integrations]\n",
      "Get all the benefits without disrupting your workflow  \n",
      "We integrate with all major finance ERPs, contract management systems, ticketing, messaging, and SSO providers.\n",
      "![Okta Icon]\n",
      "![Workday Icon]\n",
      "![QuickBooks Icon]\n",
      "![Google Icon]\n",
      "![Jira Icon]\n",
      "![Xero Icon]\n",
      "![Jumpcloud Icon]\n",
      "![Microsoft Azure Icon]\n",
      "![Amazon Icon]\n",
      "![Oracle Icon]\n",
      "![SSO Key Icon]\n",
      "![Zapier Icon]\n",
      "![Slack Icon]\n",
      "![Azure Icon]\n",
      "![FreshDesk Icon]\n",
      "![OneLogin Icon]\n",
      "[Get in Touch]\n",
      "You're definitely paying more than you should\n",
      "Let us show you the savings we can discover for you across your SaaS & cloud\n",
      "Cookie Settings\n"
     ]
    }
   ],
   "source": [
    "data = read_json_file('scraping_output_v2_raw/vertice.json')\n",
    "print(clean_scraped_content(data['/product/saas-purchasing']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Purchasing, renewing and streamlining your SaaS stack just became a whole lot easier\n",
      "Trusted by Finance and Procurement Leaders\n",
      "Clients are: MotorK, Ebury, ba&sh, Lincoln Investment, Wallbox, Matillion, PageUp, Omio, Coronado, Revel, Podimo, Haiilo, Le Collectionist, Euronext, Choco, Futureverse, Multiplica\n",
      "Benefits  \n",
      "Your SaaS purchasing has never been so under control\n",
      "Every corner of our product is designed to help you understand your SaaS stack better\n",
      "Full Stack Visibility\n",
      "Proactively keep track of your software renewals, requests, and tail spend.\n",
      "SaaS Visibility\n",
      "Usage and Analytics\n",
      "Track your license usage, helping you spot overspend and tool under-utilization.\n",
      "Analytics and Benchmarking\n",
      "Vendor Benchmarking\n",
      "Data on 16,000+ vendors, showing you the real price you ought to be paying.\n",
      "Browse Vendors\n",
      "Expert Buyers\n",
      "Our specialists partner with you to secure you the best possible deal, typically achieving savings of 20-30%.\n",
      "The Proof  \n",
      "Lose the pounds. Cut the sprawl.\n",
      "Our tech-enabled service and unrivalled experience combine to give you the best possible time and money savings\n",
      "2BN\n",
      "Managed Spend\n",
      "Across every industry and 98 countries\n",
      "4500+\n",
      "Contracts Negotiated\n",
      "Unparalled experience\n",
      "280Hrs+\n",
      "AVG saved per year\n",
      "Don't just save money\n",
      "Features\n",
      "Get full control over your SaaS\n",
      "You will have never seen your SaaS stack in so much detail, or had so many opportunities to cut costs\n",
      "Visibility\n",
      "Expert Buying\n",
      "Analytics\n",
      "Benchmarking\n",
      "Full visibility into your SaaS stack\n",
      "Get a complete view of your software spend, renewal timelines and compliance info in one simple dashboard.\n",
      "Partner with us\n",
      "Equipped with an intimate knowledge of every vendor’s sales process, our highly-experienced expert buying team works alongside yours to negotiate fairer prices and better terms.\n",
      "See the truth of your usage\n",
      "Through integrations, we show you your software utilization - and any wastage - throughout your entire stack.\n",
      "Leverage Our Vendor Benchmarks\n",
      "We maintain a live database of 16,000+ vendors' pricing and terms, so we can help you pay only what you should.\n",
      "Customer Stories\n",
      "Don’t take it from us. Hear it from them.\n",
      "The visionary startups and industry leaders who use us to optimize their spend\n",
      "Crunch\n",
      "Over $100k saved in only 3 months\n",
      "“Aside from the money savings, the time saving element has also taken a lot off my plate and other people’s plates.”\n",
      "Helena Straussman\n",
      "Operations and Transformation Director\n",
      "at\n",
      "Holded\n",
      "Onboarded in 10 days and average 20% SaaS savings\n",
      "“We’ve been amazed at the savings we have been able to generate with Vertice. It was absolutely the right decision to work with them.”\n",
      "Sam Maldonado\n",
      "VP of Finance\n",
      "Lighthouse\n",
      "$170,000 saved on a single SaaS contract\n",
      "“Vertice has been a great partner from the start by bringing amazing instant ROI and reducing the time spent negotiating contracts.”\n",
      "Matthias Geeroms\n",
      "Co-founder & CFO\n",
      "A.Team\n",
      "$330k savings in first three months and a 7x ROI overall\n",
      "“I've been able to ditch my spreadsheet of contracts and licenses now that everything is cleanly available with Vertice. I'm also saving a lot of time so it's a win all around.”\n",
      "Christopher Gonzalez\n",
      "Head of Finance\n",
      "Integrations\n",
      "Get all the benefits without disrupting your workflow  \n",
      "We integrate with all major finance ERPs, contract management systems, ticketing, messaging, and SSO providers.\n",
      "Clients are: Okta, Workday, QuickBooks, Google, Jira, Xero, Jumpcloud, Microsoft Azure, Amazon, Oracle, SSO Key, Zapier, Slack, Azure, FreshDesk, OneLogin\"\n"
     ]
    }
   ],
   "source": [
    "text = clean_scraped_content(data['/product/saas-purchasing'])\n",
    "response = llm_summary(text = text, model_name='gpt-4o-mini')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified SaaS Purchasing\n",
      "Purchasing, renewing and streamlining your SaaS stack just became a whole lot easier\n",
      "Trusted by Finance and Procurement Leaders\n",
      "Clients are: MotorK, Ebury, ba&sh, Lincoln Investment, Wallbox, Matillion, PageUp, Omio, Coronado, Revel, Podimo, Haiilo, Le Collectionist, Euronext, Choco, Futureverse, Multiplica\n",
      "Benefits  \n",
      "Your SaaS purchasing has never been so under control\n",
      "Every corner of our product is designed to help you understand your SaaS stack better\n",
      "Full Stack Visibility\n",
      "Proactively keep track of your software renewals, requests, and tail spend.\n",
      "SaaS Visibility\n",
      "Usage and Analytics\n",
      "Track your license usage, helping you spot overspend and tool under-utilization.\n",
      "Analytics and Benchmarking\n",
      "Vendor Benchmarking\n",
      "Data on 16,000+ vendors, showing you the real price you ought to be paying.\n",
      "Browse Vendors\n",
      "Expert Buyers\n",
      "Our specialists partner with you to secure you the best possible deal, typically achieving savings of 20-30%.\n",
      "The Proof  \n",
      "Lose the pounds. Cut the sprawl.\n",
      "Our tech-enabled service and unrivalled experience combine to give you the best possible time and money savings\n",
      "2BN\n",
      "Managed Spend\n",
      "Across every industry and 98 countries\n",
      "4500+\n",
      "Contracts Negotiated\n",
      "Unparalled experience\n",
      "280Hrs+\n",
      "AVG saved per year\n",
      "Don't just save money\n",
      "Features\n",
      "Get full control over your SaaS\n",
      "You will have never seen your SaaS stack in so much detail, or had so many opportunities to cut costs\n",
      "Visibility\n",
      "Expert Buying\n",
      "Analytics\n",
      "Benchmarking\n",
      "Full visibility into your SaaS stack\n",
      "Get a complete view of your software spend, renewal timelines and compliance info in one simple dashboard.\n",
      "Partner with us\n",
      "Equipped with an intimate knowledge of every vendor’s sales process, our highly-experienced expert buying team works alongside yours to negotiate fairer prices and better terms.\n",
      "See the truth of your usage\n",
      "Through integrations, we show you your software utilization - and any wastage - throughout your entire stack.\n",
      "Leverage Our Vendor Benchmarks\n",
      "We maintain a live database of 16,000+ vendors' pricing and terms, so we can help you pay only what you should.\n",
      "Customer Stories\n",
      "Don’t take it from us. Hear it from them.\n",
      "The visionary startups and industry leaders who use us to optimize their spend\n",
      "Crunch\n",
      "Over $100k saved in only 3 months\n",
      "“Aside from the money savings, the time saving element has also taken a lot off my plate and other people’s plates.”\n",
      "Helena Straussman\n",
      "Operations and Transformation Director\n",
      "at\n",
      "Holded\n",
      "Onboarded in 10 days and average 20% SaaS savings\n",
      "“We’ve been amazed at the savings we have been able to generate with Vertice. It was absolutely the right decision to work with them.”\n",
      "Sam Maldonado\n",
      "VP of Finance\n",
      "Lighthouse\n",
      "$170,000 saved on a single SaaS contract\n",
      "“Vertice has been a great partner from the start by bringing amazing instant ROI and reducing the time spent negotiating contracts.”\n",
      "Matthias Geeroms\n",
      "Co-founder & CFO\n",
      "A.Team\n",
      "$330k savings in first three months and a 7x ROI overall\n",
      "“I've been able to ditch my spreadsheet of contracts and licenses now that everything is cleanly available with Vertice. I'm also saving a lot of time so it's a win all around.”\n",
      "Christopher Gonzalez\n",
      "Head of Finance\n",
      "Integrations\n",
      "Get all the benefits without disrupting your workflow  \n",
      "We integrate with all major finance ERPs, contract management systems, ticketing, messaging, and SSO providers.\n",
      "Clients are: Okta, Workday, QuickBooks, Google, Jira, Xero, Jumpcloud, Microsoft Azure, Amazon, Oracle, SSO Key, Zapier, Slack, Azure, FreshDesk, OneLogin\n"
     ]
    }
   ],
   "source": [
    "data = read_json_file('extraction_summary/vertice_summary_str.json')\n",
    "print(clean_scraped_content(data['/product/saas-purchasing']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/110 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'llm_summary_execution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m company \u001b[38;5;129;01min\u001b[39;00m tqdm(sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mllm_summary_execution\u001b[49m(company)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm_summary_execution' is not defined"
     ]
    }
   ],
   "source": [
    "for company in tqdm(sample['processed_name'].to_list()):\n",
    "    llm_summary_execution(company)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructor\n",
    "\n",
    "https://github.com/jxnl/instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Literal\n",
    "\n",
    "class ProductDescription(BaseModel):\n",
    "    name: str = Field(..., alias='summarised name of product')\n",
    "    description: str = Field(..., alias='concise features description of the product or service')\n",
    "\n",
    "class SummaryProductDescription(BaseModel):\n",
    "    name: str = Field(..., alias='summarised name of the main product offerings of the company')\n",
    "    description: str = Field(..., alias='summary of product offering of the company')\n",
    "\n",
    "class ClientDescription(BaseModel):\n",
    "    name: str = Field(..., alias='name of the client or partner')\n",
    "    description: Optional[str] = Field(None, alias='description of the usecase')\n",
    "\n",
    "class ExtractedInformation(BaseModel):\n",
    "    product_descriptions: Optional[List[ProductDescription]] = None\n",
    "    summary_product_description: Optional[SummaryProductDescription] = None\n",
    "    client_descriptions: Optional[List[ClientDescription]] = None\n",
    "    \n",
    "class ValidatedClientDescription(BaseModel):\n",
    "    name: str = Field(..., alias='name of the client or partner')\n",
    "    entity_type: Literal[\"person\", \"company\", \"general_entity\", \"other\", \"school\"]\n",
    "    product_used: Optional[str] = Field(None, alias='summary of the product or service used by the client or partner')\n",
    "    description: Optional[str] = Field(None, alias='description of the usecase')\n",
    "\n",
    "class ValidatedExtractedInformation(BaseModel):\n",
    "    # product_descriptions: Optional[List[ProductDescription]] = None\n",
    "    # summary_product_description: Optional[SummaryProductDescription] = None\n",
    "    client_descriptions: Optional[List[ValidatedClientDescription]] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def initial_extraction(text: str, model_name: str = 'gpt-4o', additional_context: str = None) -> ExtractedInformation:\n",
    "    \n",
    "    # Patch the OpenAI client with Instructor\n",
    "    client = instructor.from_openai(OpenAI(api_key=os.getenv('OPENAI_KEY')))\n",
    "    \n",
    "    system_message = \"\"\"\n",
    "    You are an intelligent text extraction and conversion assistant. Your task is to extract structured information \n",
    "    from the given text and convert it into a structured format. \n",
    "    The output response should contain only the data extracted from the text, with no additional commentary, explanations, or extraneous information.\n",
    "    If the required information could not be found from the given source, return nothing for that field. Do not hallucinate.\n",
    "    \"\"\"\n",
    "    \n",
    "    custom_extraction_prompt = \"\"\"\n",
    "    Extract the following information from the text extracted from a webpage of a company:\n",
    "\n",
    "    1. Product Description:\n",
    "    - What service or product does the company provide?\n",
    "    - What features does the product or service have?\n",
    "    Note: If the company has more than one product or service, automatically detect and list each product with its relevant details.\n",
    "    \n",
    "    2. Summary of Product Offering:\n",
    "    - Summary of the description of the service that the company provide, taking into consideration of all the product offerings.\n",
    "    Note: Do not include any company-specific information in the summary, such as company name and location.\n",
    "    \n",
    "    3. Client Description:\n",
    "    - Name of the corporate client or partner. \n",
    "    - Description of the use case.\n",
    "    Note: Focus on the extraction of company's name, instead of individuals.\n",
    "    Note: If the description of the use case is not mentioned, it should be None.\n",
    "    \n",
    "\n",
    "    Output in a structured format.\n",
    "    \"\"\"\n",
    "    \n",
    "    rule_prompt = \"\"\"\n",
    "                Here are the rules that you need to adhere:\n",
    "                    ## Rules:\n",
    "                    - The aim is to achieve simplicity and clarity in the extracted text.\n",
    "                    - Make sure to answer in the structured format.\n",
    "                    - If no information is provided for any of the fields, return nothing of that field.\n",
    "                    - DO NOT HALLUCINATE.\n",
    "                \"\"\"\n",
    "    \n",
    "    extraction_prompt = f\"\"\"\n",
    "    {system_message}\n",
    "    {custom_extraction_prompt}\n",
    "    \"\"\"\n",
    "    \n",
    "    if additional_context:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name, \n",
    "            response_model=ExtractedInformation,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": extraction_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"Use the given text to extract information: {text}\"},\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"Here are some additional descriptions about this company for your reference:\n",
    "                                                {additional_context}\"\"\"},\n",
    "                {\"role\": \"user\", \"content\": rule_prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name, \n",
    "            response_model=ExtractedInformation,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": extraction_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"Use the given text to extract information: {text}\"},\n",
    "                {\"role\": \"user\", \"content\": rule_prompt}\n",
    "            ]\n",
    "        )\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_validation(products: list, clients: list, summary: dict, model_name: str = 'gpt-4o') -> ValidatedExtractedInformation:\n",
    "    \n",
    "    # Patch the OpenAI client with Instructor\n",
    "    client = instructor.from_openai(OpenAI(api_key=os.getenv('OPENAI_KEY')))\n",
    "    \n",
    "    system_message = \"\"\"\n",
    "    You are an intelligent text extraction and conversion assistant. Your task is to validate the client information, classify the client names into different entity types, and determine which product is likely used by the client. \n",
    "    The output response should contain only the data validated and assigned, with no additional commentary, explanations, or extraneous information.\n",
    "    If the required information could not be found from the given source, return nothing for that field. Do not hallucinate.\n",
    "    \"\"\"\n",
    "    \n",
    "    product_info = \"\\n\".join([f\"Product: {p['name']}; Description: {p['description']}\" for p in products])\n",
    "    client_info = \"\\n\".join([f\"Client: {c['name']}; Description: {c['description']}\" for c in clients])\n",
    "    summary_info = f\"{summary['name']}: {summary['description']}\"\n",
    "    \n",
    "    few_shot_examples = \"\"\"\n",
    "        ## Example 1:\n",
    "        Client Name: Mike Johnson, CEO of TechCorp\n",
    "        Entity_type: person\n",
    "        - Reason: Mike Johnson is the name of a person. \n",
    "        \n",
    "        ## Example 2:\n",
    "        Client Name: Government\n",
    "        Entity_type: general_entity\n",
    "        - Reason: \"Government\" is a general entity, not a specific company.\n",
    "\n",
    "        ## Example 3:\n",
    "        Client Name: Innovative Solutions LLC\n",
    "        Entity_type: company\n",
    "        - Reason: Innovative Solutions LLC is a specific company name.\n",
    "        \n",
    "        ## Example 4:\n",
    "        Client Name: A US resort\n",
    "        Entity_type: general_entity\n",
    "        - Reason: \"A US resort\" is a general description, not a specific company name.\n",
    "    \n",
    "        ## Example 5: \n",
    "        Client Name: University College London\n",
    "        Entity_type: school\n",
    "        - Reason: University College London is a specific school name.\n",
    "    \"\"\"\n",
    "\n",
    "    validation_prompt = f\"\"\"\n",
    "    {system_message}\n",
    "    Here is the product information extracted:\n",
    "    {product_info}\n",
    "    \n",
    "    Here is the summary of product offerings of the company:\n",
    "    {summary_info}\n",
    "    \n",
    "    Here are the clients and their use cases:\n",
    "    {client_info}\n",
    "    \n",
    "    Your task is to:\n",
    "    1. Classify each client name into one of the following entity types: person, company, general_entity, school, or other.\n",
    "       Note: the entity type \"company\" should be given to specific companies, with company names.\n",
    "    2. Based on the product descriptions and client use cases, assign the most likely product used by each client. \n",
    "       If you are not confident about which product the client uses, return None for that field.\n",
    "\n",
    "    Here are some examples regarding the classifying clients into different entity types:\n",
    "    {few_shot_examples}\n",
    "\n",
    "    Output in a structured format.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        response_model=ValidatedExtractedInformation,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": validation_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"\"\"\n",
    "                Here are the rules that you need to adhere:\n",
    "                ## Rules:\n",
    "                - Classify each client name into one of the following entity types: person, company, general_entity, school, or other.\n",
    "                - Assign the most likely product used by each client based on the provided product descriptions and use cases.\n",
    "                - If the product used is not clear, return None for that field.\n",
    "                - Make sure to answer in the structured format.\n",
    "                - DO NOT HALLUCINATE.\n",
    "            \"\"\"},\n",
    "        ]\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample run\n",
    "\n",
    "# Example usage for the first prompt\n",
    "text = \"\"\"\n",
    "Our company offers innovative cloud solutions that help businesses streamline their operations. Our key features include scalability, security, and ease of use.\n",
    "\n",
    "We partner with leading firms such as TechCorp and SoftInc to deliver top-notch services. For example, TechCorp uses our cloud solutions to improve their data management, resulting in a 30% increase in efficiency.\n",
    "\n",
    "Our client, SoftInc, has integrated our services into their workflow, leading to significant improvements in their project turnaround times.\n",
    "\n",
    "Our platform and service are trusted by these innovative companies:\n",
    "![Nationwide Logo]\n",
    "![Freedom 365 Logo]\n",
    "![Bestow Logo]\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "initial_response = initial_extraction(text).dict()\n",
    "\n",
    "# Example usage for the second prompt\n",
    "\n",
    "products = initial_response['product_descriptions'] if initial_response['product_descriptions'] else []\n",
    "clients = initial_response['client_descriptions'] if initial_response['client_descriptions'] else []\n",
    "summary = initial_response['summary_product_description']\n",
    "\n",
    "validated_response = information_validation(products, clients, summary)\n",
    "print(validated_response.dict())\n",
    "\n",
    "result = initial_response\n",
    "result['validated_client_description'] = validated_response.dict()['client_descriptions']\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_extraction_execution(processed_name:str, include_additional_context:bool = True, overwrite:bool = False):\n",
    "\n",
    "    summary_file_path = f'extraction_summary_v2/{processed_name}_summary_str.json'\n",
    "    extraction_file_path = f'extraction_output_v2/{processed_name}_extraction.json'\n",
    "    \n",
    "    if not overwrite and os.path.exists(extraction_file_path):\n",
    "        print(f\"Company: {processed_name}; Skipping extraction as the extraction file already exists and overwrite is set to False.\")\n",
    "        return None\n",
    "    else:\n",
    "        if os.path.exists(summary_file_path):\n",
    "            with open(summary_file_path, 'r') as file:\n",
    "                summary = json.load(file)\n",
    "\n",
    "            combined_summary = f\"## Main Page:\\n {summary['main_page']}\\n----------------\\n\"\n",
    "\n",
    "            for endpoint, text in summary.items():\n",
    "                if endpoint not in [\"main_page\", \"timestamp\", \"processed_company\", \"url\"]:\n",
    "                    combined_summary += f\"## {endpoint}:\\n{text}\\n----------------\\n\"\n",
    "            \n",
    "            print(f\"Company: {processed_name}; Information extraction begins.\")\n",
    "            if include_additional_context:\n",
    "                context = get_additional_info(processed_name, 'description')\n",
    "                \n",
    "                print(f'Company: {processed_name}; Estimated Cost: ${calculate_cost(combined_summary + context)}')\n",
    "                print(f'Company: {processed_name}; Pitchbook description obtained: {context}')\n",
    "                \n",
    "                initial_response = initial_extraction(text = combined_summary, \n",
    "                                                additional_context = context).dict()\n",
    "                \n",
    "            else:\n",
    "                print(f'Company: {processed_name}; Estimated Cost: ${calculate_cost(combined_summary)}')\n",
    "                initial_response = initial_extraction(text = combined_summary, \n",
    "                                            additional_context = None).dict()\n",
    "            \n",
    "            print(f'Company: {processed_name}; PART 1 - Initial extraction is completed.')\n",
    "            \n",
    "            result = initial_response\n",
    "            \n",
    "            if initial_response['client_descriptions']:\n",
    "                products = initial_response['product_descriptions'] if initial_response['product_descriptions'] else []\n",
    "                clients = initial_response['client_descriptions'] if initial_response['client_descriptions'] else []\n",
    "                summary = initial_response['summary_product_description']\n",
    "\n",
    "                validated_response = information_validation(products, clients, summary)\n",
    "                print(f'Company: {processed_name}; PART 2 - Information validation is completed.')\n",
    "                result['validated_client_descriptions'] = validated_response.dict()['client_descriptions']\n",
    "                \n",
    "            else:\n",
    "                print(f'Company: {processed_name}; PART 2 - Skipped, due to lack of client information.')\n",
    "                result['validated_client_descriptions'] = None\n",
    "            \n",
    "            current_dateTime = datetime.now(pytz.timezone('Etc/GMT'))\n",
    "            result['timestamp'] = current_dateTime.strftime(format = \"%Y-%m-%d %H:%M\") + ' Etc/GMT'\n",
    "            result['processed_company'] = processed_name\n",
    "            result['url'] = \"https://\" + get_additional_info(processed_name, 'processed_url')\n",
    "\n",
    "            write_json_file(extraction_file_path, result)\n",
    "            \n",
    "            return result\n",
    "        else:\n",
    "            print(f'Summary file: {summary_file_path} does not exist.')\n",
    "            return None\n",
    "\n",
    "def add_client_url_to_extraction_output(processed_name:str, file_path:str = 'extraction_output_v2'):\n",
    "    data = read_json_file(f'{file_path}/{processed_name}_extraction.json')\n",
    "    \n",
    "    if data['validated_client_descriptions']:\n",
    "        for client in data['validated_client_descriptions']:\n",
    "            if client['entity_type'] != 'company':\n",
    "                client['url'] = None\n",
    "            else:\n",
    "                url = get_and_verify_client_link(client['name'], verbose = False)\n",
    "                client['url'] = url\n",
    "            \n",
    "        write_json_file(f'{file_path}/{processed_name}_extraction.json', data)\n",
    "        print(f\"Company: {processed_name}; Client is extracted.\")\n",
    "    else:\n",
    "        print(f\"Company: {processed_name}; No clients' information.\")\n",
    "        \n",
    "\n",
    "def get_embedding(text:str, embedding_model:str=\"text-embedding-3-small\"):\n",
    "   client_openai = OpenAI(api_key=os.getenv('OPENAI_KEY'))\n",
    "   \n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client_openai.embeddings.create(input = [text], model=embedding_model).data[0].embedding\n",
    "\n",
    "\n",
    "def get_product_embedding(processed_name:str, embedding_model:str=\"text-embedding-3-small\"):\n",
    "    file_path = f'extraction_output_v2/{processed_name}_extraction.json'\n",
    "    \n",
    "    data = read_json_file(file_path)\n",
    "    # Check wheather embedding has already been done\n",
    "    if 'name_embedding' in data['summary_product_description']:\n",
    "        print(f'Company: {processed_name}; Embedding has already been done.')\n",
    "        pass\n",
    "    else:\n",
    "        product_lst = data['product_descriptions']\n",
    "        for product in product_lst:\n",
    "            product['description_embedding'] = get_embedding(text = product['description'],\n",
    "                                                                embedding_model = embedding_model)\n",
    "            product['name_embedding'] = get_embedding(text = product['name'],\n",
    "                                                                embedding_model = embedding_model)\n",
    "\n",
    "\n",
    "        summary_product = data['summary_product_description']\n",
    "        summary_product['description_embedding'] = get_embedding(text = summary_product['description'],\n",
    "                                                                embedding_model = embedding_model)\n",
    "        summary_product['name_embedding'] = get_embedding(text = summary_product['name'],\n",
    "                                                                embedding_model = embedding_model)\n",
    "        print(f'Company: {processed_name}; Embedding is completed.')\n",
    "        write_json_file(file_path, data)\n",
    "    \n",
    "    return data\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_extraction_execution(processed_name = 'vertice', \n",
    "                         include_additional_context = True, \n",
    "                         overwrite = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company: bankerslab; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: bankerslab; No clients' information.\n",
      "Company: bankerslab; Embedding has already been done.\n",
      "Company: estimize; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: estimize; Client is extracted.\n",
      "Company: estimize; Embedding has already been done.\n",
      "Company: avyst; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: avyst; Client is extracted.\n",
      "Company: avyst; Embedding has already been done.\n",
      "Company: bennie; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: bennie; Client is extracted.\n",
      "Company: bennie; Embedding has already been done.\n",
      "Company: vertice; Information extraction begins.\n",
      "Company: vertice; Estimated Cost: $0.013940000000000001\n",
      "Company: vertice; Pitchbook description obtained: Developer a spend optimization platform designed to help save on annual software expenditure. The company's platform empowers companies of every size and industry to get more visibility and control of their software and cloud spending and leverages automation to deliver guaranteed cost savings, enabling companies to view, control, and save on both Software as a service (SaaS) and cloud costs with an integrated unified offering.\n",
      "Company: vertice; PART 1 - Initial extraction is completed.\n",
      "Company: vertice; PART 2 - Information validation is completed.\n",
      "Company: vertice; Client is extracted.\n",
      "Company: vertice; Embedding is completed.\n",
      "Company: hemlane; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: hemlane; Client is extracted.\n",
      "Company: hemlane; Embedding has already been done.\n",
      "Company: naturealpha; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: naturealpha; Client is extracted.\n",
      "Company: naturealpha; Embedding has already been done.\n",
      "Company: nexben; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: nexben; No clients' information.\n",
      "Company: nexben; Embedding has already been done.\n",
      "Company: ledger_works; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: ledger_works; Client is extracted.\n",
      "Company: ledger_works; Embedding has already been done.\n",
      "Company: vesta; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: vesta; Client is extracted.\n",
      "Company: vesta; Embedding has already been done.\n",
      "Company: direct; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company Luxury RV Rentals LV has error: list index out of range\n",
      "Company: direct; Client is extracted.\n",
      "Company: direct; Embedding has already been done.\n",
      "Company: massive; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: massive; Client is extracted.\n",
      "Company: massive; Embedding has already been done.\n",
      "Company: missionmark; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: missionmark; Client is extracted.\n",
      "Company: missionmark; Embedding has already been done.\n",
      "Company: new_constructs; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: new_constructs; Client is extracted.\n",
      "Company: new_constructs; Embedding has already been done.\n",
      "Company: aggregion; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: aggregion; Client is extracted.\n",
      "Company: aggregion; Embedding has already been done.\n",
      "Company: infogrid; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: infogrid; Client is extracted.\n",
      "Company: infogrid; Embedding has already been done.\n",
      "Company: additive; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: additive; No clients' information.\n",
      "Company: additive; Embedding has already been done.\n",
      "Company: 9fin; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: 9fin; Client is extracted.\n",
      "Company: 9fin; Embedding has already been done.\n",
      "Company: adaptive; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: adaptive; Client is extracted.\n",
      "Company: adaptive; Embedding has already been done.\n",
      "Company: niloom_ai; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: niloom_ai; No clients' information.\n",
      "Company: niloom_ai; Embedding has already been done.\n",
      "Company: aer_compliance; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: aer_compliance; No clients' information.\n",
      "Company: aer_compliance; Embedding has already been done.\n",
      "Company: dexit; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: dexit; No clients' information.\n",
      "Company: dexit; Embedding has already been done.\n",
      "Company: harness_data_intelligence; Skipping extraction as the extraction file already exists and overwrite is set to False.\n",
      "Company: harness_data_intelligence; Client is extracted.\n",
      "Company: harness_data_intelligence; Embedding has already been done.\n"
     ]
    }
   ],
   "source": [
    "doc_list = os.listdir('extraction_summary_v2')\n",
    "for doc in doc_list:\n",
    "    processed_name = doc.replace('_summary_str.json', '')\n",
    "    try:\n",
    "        llm_extraction_execution(processed_name = processed_name, \n",
    "                        include_additional_context = True, \n",
    "                        overwrite = False)\n",
    "        add_client_url_to_extraction_output(processed_name = processed_name)\n",
    "        get_product_embedding(processed_name = processed_name)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Error occured on company {processed_name}: e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code used to re-validate the client description:\n",
    "\n",
    "processed_name = 'vertice'\n",
    "    \n",
    "extraction_file_path = f'extraction_output_v2/{processed_name}_extraction.json'\n",
    "initial_response = read_json_file(extraction_file_path)\n",
    "if initial_response['client_descriptions']:\n",
    "    products = initial_response['product_descriptions'] if initial_response['product_descriptions'] else []\n",
    "    clients = initial_response['client_descriptions'] if initial_response['client_descriptions'] else []\n",
    "    summary = initial_response['summary_product_description']\n",
    "\n",
    "    validated_response = information_validation(products, clients, summary)\n",
    "    print(f'Company: {processed_name}; PART 2 - Information validation is completed.')\n",
    "    result['validated_client_descriptions'] = validated_response.dict()['client_descriptions']\n",
    "    \n",
    "else:\n",
    "    print(f'Company: {processed_name}; PART 2 - Skipped, due to lack of client information.')\n",
    "    result['validated_client_descriptions'] = None\n",
    "\n",
    "current_dateTime = datetime.now(pytz.timezone('Etc/GMT'))\n",
    "result['timestamp'] = current_dateTime.strftime(format = \"%Y-%m-%d %H:%M\") + ' Etc/GMT'\n",
    "result['processed_company'] = processed_name\n",
    "result['url'] = \"https://\" + get_additional_info(processed_name, 'processed_url')\n",
    "write_json_file(extraction_file_path, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_file_path = f'extraction_output_v2/9fin_extraction.json'\n",
    "initial_response = read_json_file(extraction_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Product: Data & Analytics Platform; Description: Provides AI-powered financial data and analytics. Features real-time market news, key data on high-yield bonds, deal tracking, financial profiles, predictive analytics, search functionality, and ESG data.\\nProduct: Comparables; Description: Benchmark prior transactions, bonds, loans, or company profiles using over 300 credit metrics.\\nProduct: Earnings; Description: AI transcripts and instant analysis for earnings reports.\\nProduct: Search; Description: Powerful search tool for thousands of documents text-searchable by any keyword or phrase.\\nProduct: ESG; Description: A full suite of Environmental, Social, and Governance data and analysis.\\nProduct: Distressed and Restructuring; Description: Tools to spot undervalued credits and potential future restructurings.\\nProduct: News; Description: Aggregates news from 2,000 sources using AI and delivers it quickly.\\nProduct: Financials; Description: Full financial profiles with 3 statements, KPIs, segment splits, and credit metrics traced to source documents.\\nProduct: Covenants; Description: New deal analysis and covenant comparison tools.\\nProduct: Deal predictions; Description: Predicts refinancing, restructuring, and capital markets activity 12 months in advance.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = initial_response['product_descriptions']\n",
    "product_info = \"\\n\".join([f\"Product: {p['name']}; Description: {p['description']}\" for p in products])\n",
    "\n",
    "product_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Data & Analytics Platform',\n",
       "  'description': 'Provides AI-powered financial data and analytics. Features real-time market news, key data on high-yield bonds, deal tracking, financial profiles, predictive analytics, search functionality, and ESG data.'},\n",
       " {'name': 'Comparables',\n",
       "  'description': 'Benchmark prior transactions, bonds, loans, or company profiles using over 300 credit metrics.'},\n",
       " {'name': 'Earnings',\n",
       "  'description': 'AI transcripts and instant analysis for earnings reports.'},\n",
       " {'name': 'Search',\n",
       "  'description': 'Powerful search tool for thousands of documents text-searchable by any keyword or phrase.'},\n",
       " {'name': 'ESG',\n",
       "  'description': 'A full suite of Environmental, Social, and Governance data and analysis.'},\n",
       " {'name': 'Distressed and Restructuring',\n",
       "  'description': 'Tools to spot undervalued credits and potential future restructurings.'},\n",
       " {'name': 'News',\n",
       "  'description': 'Aggregates news from 2,000 sources using AI and delivers it quickly.'},\n",
       " {'name': 'Financials',\n",
       "  'description': 'Full financial profiles with 3 statements, KPIs, segment splits, and credit metrics traced to source documents.'},\n",
       " {'name': 'Covenants',\n",
       "  'description': 'New deal analysis and covenant comparison tools.'},\n",
       " {'name': 'Deal predictions',\n",
       "  'description': 'Predicts refinancing, restructuring, and capital markets activity 12 months in advance.'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company 9fin's clients are recorded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/24 [00:00<00:02,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company new_constructs's clients are recorded.\n",
      "Company .DS_Store has error: 'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4/24 [00:00<00:02,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company adaptive's clients are recorded.\n",
      "Company hemlane's clients are recorded.\n",
      "Company niloom_ai has error: 'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 8/24 [00:01<00:02,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company bennie's clients are recorded.\n",
      "Company infogrid's clients are recorded.\n",
      "Company additive has error: 'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 11/24 [00:01<00:02,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company vertice's clients are recorded.\n",
      "Company avyst's clients are recorded.\n",
      "Company estimize's clients are recorded.\n",
      "Company missionmark's clients are recorded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 16/24 [00:02<00:01,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company vesta's clients are recorded.\n",
      "Company aer_compliance has error: 'NoneType' object is not iterable\n",
      "Company naturealpha's clients are recorded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 17/24 [00:03<00:01,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company aggregion's clients are recorded.\n",
      "Company dexit has error: 'NoneType' object is not iterable\n",
      "Company harness_data_intelligence's clients are recorded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 22/24 [00:03<00:00,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company direct's clients are recorded.\n",
      "Company nexben has error: 'NoneType' object is not iterable\n",
      "Company massive's clients are recorded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Sceptre has already been recorded.\n",
      "Company ledger_works's clients are recorded.\n",
      "Company bankerslab has error: 'NoneType' object is not iterable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "client_info = read_json_file('data/client_info.json')\n",
    "# client_info = {}\n",
    "\n",
    "doc_list = os.listdir('extraction_output_v2')\n",
    "\n",
    "for doc in tqdm(doc_list):\n",
    "    try:\n",
    "        processed_name = doc.replace('_extraction.json', '')\n",
    "        data = read_json_file(f'extraction_output_v2/{doc}')\n",
    "\n",
    "        for client in data['validated_client_descriptions']:\n",
    "            if client['entity_type'] != 'company':\n",
    "                continue\n",
    "            # If a company's name already exists in the dictionary\n",
    "            if client['name'] in client_info:\n",
    "                \n",
    "                # If its service provider does not appear in the saved list, then append it\n",
    "                if processed_name not in client_info[client['name']]['service_provider_processed']:\n",
    "                    client_info[client['name']]['service_provider_processed'].append(processed_name)\n",
    "                    client_info[client['name']]['service_provider'].append(get_additional_info(processed_name, 'companies'))\n",
    "                    client_info[client['name']]['service_provider_url'].append('https://' + get_additional_info(processed_name, 'processed_url'))\n",
    "                else:\n",
    "                    print(f'Company {client[\"name\"]} has already been recorded.')\n",
    "            \n",
    "            # If a company's name already does not exist, add the new company\n",
    "            else:\n",
    "                client_info[client['name']] = {'processed_name': process_company_name(client['name']),\n",
    "                                    'url': client['url'],\n",
    "                                    'service_provider_processed': [processed_name],\n",
    "                                    'service_provider': [get_additional_info(processed_name, 'companies')],\n",
    "                                    'service_provider_url': ['https://' + get_additional_info(processed_name, 'processed_url')]\n",
    "                                    }\n",
    "        print(f\"Company {data['processed_company']}'s clients are recorded.\")\n",
    "    except Exception as e:\n",
    "        print(f'Company {processed_name} has error: {e}')\n",
    "        \n",
    "write_json_file('data/client_info.json', client_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:   0%|          | 0/104 [00:00<?, ?it/s]/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.bloomberg.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bloomberg.com/professional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.bloomberg.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:   1%|          | 1/104 [00:00<01:06,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.bloomberg.com/professional as it already exists and overwrite is set to False.\n",
      "https://www.iexcloud.io\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.iexcloud.io'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:   3%|▎         | 3/104 [00:02<01:34,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.iexcloud.io as it already exists and overwrite is set to False.\n",
      "Skipping https://www.iexcloud.io/product-bulletin as it already exists and overwrite is set to False.\n",
      "https://www.wisdomtree.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.wisdomtree.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:   4%|▍         | 4/104 [00:03<01:21,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.wisdomtree.com as it already exists and overwrite is set to False.\n",
      "https://www.reventbuilds.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.reventbuilds.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'reventbuilds.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:   7%|▋         | 7/104 [00:06<01:24,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.reventbuilds.com as it already exists and overwrite is set to False.\n",
      "https://www.drakeconstructionservices.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.drakeconstructionservices.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.drakeconstructionservices.com as it already exists and overwrite is set to False.\n",
      "Skipping https://www.drakeconstructionservices.com/index.asp as it already exists and overwrite is set to False.\n",
      "Skipping https://www.drakeconstructionservices.com/project_details.asp?id=111 as it already exists and overwrite is set to False.\n",
      "Skipping https://www.drakeconstructionservices.com/project_details.asp?id=136 as it already exists and overwrite is set to False.\n",
      "Skipping https://www.drakeconstructionservices.com/project_details.asp?id=52 as it already exists and overwrite is set to False.\n",
      "Skipping https://www.drakeconstructionservices.com/contact-us.asp as it already exists and overwrite is set to False.\n",
      "Skipping https://www.drakeconstructionservices.com/project_details.asp?id=103 as it already exists and overwrite is set to False.\n",
      "Skipping https://www.drakeconstructionservices.com/current-projects.asp as it already exists and overwrite is set to False.\n",
      "Scraping https://www.drakeconstructionservices.com/privacy-policy.asp.\n",
      "Scraping https://www.drakeconstructionservices.com/project_details.asp?id=133.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:   9%|▊         | 9/104 [00:14<03:23,  2.14s/it]/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.airbnb.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.airbnb.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.airbnb.co.uk'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:  14%|█▍        | 15/104 [00:16<01:27,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.airbnb.com as it already exists and overwrite is set to False.\n",
      "https://www.thoropass.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.thoropass.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'thoropass.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:  15%|█▌        | 16/104 [00:17<01:31,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.thoropass.com as it already exists and overwrite is set to False.\n",
      "Skipping https://www.thoropass.com/solutions/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.thoropass.com/company/become-a-partner/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.thoropass.com/platform/service-partnerships/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.thoropass.com/platform/penetration-testing/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.thoropass.com/customers/monit/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.thoropass.com/platform/due-diligence-questionnaire/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.thoropass.com/solutions/maintain-compliance/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.thoropass.com/customers/elestio/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.thoropass.com/platform/amazon-web-services/ as it already exists and overwrite is set to False.\n",
      "https://www.fahertybrand.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fahertybrand.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'fahertybrand.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:  16%|█▋        | 17/104 [00:19<01:42,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.fahertybrand.com as it already exists and overwrite is set to False.\n",
      "Skipping https://www.fahertybrand.com/products/isha-dress-blue-mini-stripe-3 as it already exists and overwrite is set to False.\n",
      "Skipping https://www.fahertybrand.com/products/inlet-knit-blazer-deep-navy-melange as it already exists and overwrite is set to False.\n",
      "Skipping https://www.fahertybrand.com/products/sunwashed-tee-white as it already exists and overwrite is set to False.\n",
      "Skipping https://www.fahertybrand.com/products/sunwashed-pocket-tee-white-2 as it already exists and overwrite is set to False.\n",
      "Skipping https://www.fahertybrand.com/products/belt-loop-all-day-shorts-7-in7-in-olive as it already exists and overwrite is set to False.\n",
      "Skipping https://www.fahertybrand.com/products/belt-loop-all-day-shorts-7-stone as it already exists and overwrite is set to False.\n",
      "Skipping https://www.fahertybrand.com/pages/native-partnerships as it already exists and overwrite is set to False.\n",
      "Skipping https://www.fahertybrand.com/products/inlet-blazer-heather-grey as it already exists and overwrite is set to False.\n",
      "https://www.formstack.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.formstack.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.formstack.com as it already exists and overwrite is set to False.\n",
      "Skipping https://www.formstack.com/partners as it already exists and overwrite is set to False.\n",
      "Skipping https://www.formstack.com/products as it already exists and overwrite is set to False.\n",
      "Skipping https://www.formstack.com/customer-stories as it already exists and overwrite is set to False.\n",
      "Skipping https://www.formstack.com/solutions as it already exists and overwrite is set to False.\n",
      "Skipping https://www.formstack.com/find-a-partner as it already exists and overwrite is set to False.\n",
      "Scraping https://www.formstack.com/products/online-forms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:  17%|█▋        | 18/104 [00:27<03:24,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.formstack.com/legal/ccpa-information-for-customers as it already exists and overwrite is set to False.\n",
      "Skipping https://www.formstack.com/solutions/employee-onboarding as it already exists and overwrite is set to False.\n",
      "Skipping https://www.formstack.com/solutions/customer-satisfaction-surveys as it already exists and overwrite is set to False.\n",
      "https://www.rokt.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.rokt.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:  19%|█▉        | 20/104 [00:27<02:16,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.rokt.com as it already exists and overwrite is set to False.\n",
      "Skipping https://www.rokt.com/partners as it already exists and overwrite is set to False.\n",
      "Skipping https://www.rokt.com/case-studies/rokt-ecommerce-delivers-8x-more-monthly-revenue-than-google-adsense/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.rokt.com/case-studies/schwans-home-delivery-speeds-up-their-customer-acquisition-with-rokt-ads/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.rokt.com/case-studies/flamingo-shaves-off-their-cpa-by-60-with-rokt-ads/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.rokt.com/customers as it already exists and overwrite is set to False.\n",
      "Skipping https://www.rokt.com/case-studies as it already exists and overwrite is set to False.\n",
      "Skipping https://www.rokt.com/case-studies/the-vitamin-shoppe-adds-profit-while-improving-their-customer-experience-with-rokt/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.rokt.com/solutions as it already exists and overwrite is set to False.\n",
      "Skipping https://www.rokt.com/customer-examples as it already exists and overwrite is set to False.\n",
      "https://www.nylas.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.nylas.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.nylas.com as it already exists and overwrite is set to False.\n",
      "Skipping https://www.nylas.com/partners/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.nylas.com/solutions/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.nylas.com/case-studies/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.nylas.com/products/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.nylas.com/products/calendar-api/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.nylas.com/solutions/travel-and-hospitality/ as it already exists and overwrite is set to False.\n",
      "Scraping https://www.nylas.com/solutions/financial-technology/.\n",
      "Scraping https://www.nylas.com/case-study/dialpad/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:  20%|██        | 21/104 [00:37<04:26,  3.20s/it]/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.warbyparker.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:  21%|██        | 22/104 [00:37<03:28,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.nylas.com/company/contact-platform-specialist/ as it already exists and overwrite is set to False.\n",
      "https://www.warbyparker.com\n",
      "Failed to access https://www.warbyparker.com. Status code: 403\n",
      "Company Warby Parker has error: object of type 'NoneType' has no len()\n",
      "https://www.bonusly.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.bonusly.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'bonusly.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.bonusly.com as it already exists and overwrite is set to False.\n",
      "Scraping https://www.bonusly.com/features/product-overview.\n",
      "Rate limit exceeded. Retrying after 59.999998807907104 seconds.\n",
      "Skipping https://www.bonusly.com/customers/solugenix as it already exists and overwrite is set to False.\n",
      "Scraping https://www.bonusly.com/customers/rechat-elevates-engagement-and-culture-with-bonusly.\n",
      "Skipping https://www.bonusly.com/customers/surveymonkey as it already exists and overwrite is set to False.\n",
      "Scraping https://www.bonusly.com/product/achieve.\n",
      "Scraping https://www.bonusly.com/product/appreciate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:  22%|██▏       | 23/104 [01:52<26:35, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.bonusly.com/customers/nexthink as it already exists and overwrite is set to False.\n",
      "Skipping https://www.bonusly.com/customers/toast as it already exists and overwrite is set to False.\n",
      "Skipping https://www.bonusly.com/customers/headspace as it already exists and overwrite is set to False.\n",
      "https://www.ltse.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ltse.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ltse.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:  23%|██▎       | 24/104 [01:58<21:40, 16.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.ltse.com as it already exists and overwrite is set to False.\n",
      "Skipping https://www.ltse.com/trading/customer-notices as it already exists and overwrite is set to False.\n",
      "Skipping https://www.ltse.com/listings/partner-with-ltse as it already exists and overwrite is set to False.\n",
      "https://www.superhuman.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.superhuman.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'superhuman.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.superhuman.com.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:  24%|██▍       | 25/104 [02:04<17:42, 13.44s/it]/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.pliancy.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.pliancy.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'pliancy.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:  25%|██▌       | 26/104 [02:07<13:40, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.pliancy.com as it already exists and overwrite is set to False.\n",
      "Skipping https://www.pliancy.com/clients/satellite-bio/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.pliancy.com/services as it already exists and overwrite is set to False.\n",
      "Skipping https://www.pliancy.com/clients/photys-therapeutics as it already exists and overwrite is set to False.\n",
      "Skipping https://www.pliancy.com/clients/eclipse as it already exists and overwrite is set to False.\n",
      "https://www.himarley.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.himarley.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.himarley.com.\n",
      "Skipping https://www.himarley.com/solutions-overview/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.himarley.com/resource-center/?resource-type=case-study as it already exists and overwrite is set to False.\n",
      "Skipping https://www.himarley.com/customers as it already exists and overwrite is set to False.\n",
      "Skipping https://www.himarley.com/service/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.himarley.com/customers/ as it already exists and overwrite is set to False.\n",
      "Scraping https://www.himarley.com/platform-overview.\n",
      "Rate limit exceeded. Retrying after 59.999995946884155 seconds.\n",
      "Skipping https://www.himarley.com/partners as it already exists and overwrite is set to False.\n",
      "Skipping https://www.himarley.com/customer-success/ as it already exists and overwrite is set to False.\n",
      "Scraping https://www.himarley.com/platform-overview/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:  26%|██▌       | 27/104 [03:16<34:53, 27.19s/it]/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.rippling.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.rippling.com\n",
      "Skipping https://www.rippling.com as it already exists and overwrite is set to False.\n",
      "Skipping https://www.rippling.com/platform as it already exists and overwrite is set to False.\n",
      "Scraping https://www.rippling.com/customers.\n",
      "Skipping https://www.rippling.com/global-benefit-solution as it already exists and overwrite is set to False.\n",
      "Scraping https://www.rippling.com/customers/morning-consult.\n",
      "Skipping https://www.rippling.com/industries/financial-services as it already exists and overwrite is set to False.\n",
      "Scraping https://www.rippling.com/resources/pitfalls-modern-spend-solutions.\n",
      "Scraping https://www.rippling.com/customers/harver.\n",
      "Skipping https://www.rippling.com/customers/appcues as it already exists and overwrite is set to False.\n",
      "Scraping https://www.rippling.com/customers/andros.\n",
      "Rate limit exceeded. Retrying after 59.999998807907104 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:  27%|██▋       | 28/104 [04:32<52:12, 41.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.crisistextline.org\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.crisistextline.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:  28%|██▊       | 29/104 [04:33<36:52, 29.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.crisistextline.org as it already exists and overwrite is set to False.\n",
      "Skipping https://www.crisistextline.org/partnerships/ as it already exists and overwrite is set to False.\n",
      "https://www.interpretek.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.interpretek.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'interpretek.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:  29%|██▉       | 30/104 [04:35<26:16, 21.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.interpretek.com as it already exists and overwrite is set to False.\n",
      "Skipping https://www.interpretek.com/case-studies/ as it already exists and overwrite is set to False.\n",
      "https://www.softbankrobotics.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.softbankrobotics.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.softbankrobotics.com.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:  30%|██▉       | 31/104 [04:38<19:15, 15.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.softbankrobotics.com/solution/ as it already exists and overwrite is set to False.\n",
      "https://www.holded.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.holded.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:  34%|███▎      | 35/104 [04:38<06:50,  5.95s/it]/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.encompass.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:  37%|███▋      | 38/104 [04:38<03:56,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.holded.com as it already exists and overwrite is set to False.\n",
      "Skipping https://www.holded.com/professional-services as it already exists and overwrite is set to False.\n",
      "Skipping https://www.holded.com/success-cases/ as it already exists and overwrite is set to False.\n",
      "Skipping https://www.holded.com/success-cases as it already exists and overwrite is set to False.\n",
      "https://www.encompass.com\n",
      "Failed to access https://www.encompass.com. Status code: 403\n",
      "Company Encompass has error: object of type 'NoneType' has no len()\n",
      "https://www.vertafore.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.vertafore.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.vertafore.com.\n",
      "Skipping https://www.vertafore.com/solutions-mgas as it already exists and overwrite is set to False.\n",
      "Skipping https://www.vertafore.com/products as it already exists and overwrite is set to False.\n",
      "Skipping https://www.vertafore.com/solutions-agencies as it already exists and overwrite is set to False.\n",
      "Skipping https://www.vertafore.com/solutions-carriers as it already exists and overwrite is set to False.\n",
      "Scraping https://www.vertafore.com/products/insurlink.\n",
      "Scraping https://www.vertafore.com/products/mga-systems.\n",
      "Scraping https://www.vertafore.com/products/sircon-onboarding-and-self-service.\n",
      "Scraping https://www.vertafore.com/why-vertafore/orange-partner-program.\n",
      "Rate limit exceeded. Retrying after 59.99999690055847 seconds.\n",
      "Scraping https://www.vertafore.com/products/vertafore-client-communications.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:  38%|███▊      | 39/104 [06:00<17:32, 16.20s/it]/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.piiac.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'piiac.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.piiac.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:  39%|███▉      | 41/104 [06:01<11:43, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping https://www.piiac.com as it already exists and overwrite is set to False.\n",
      "https://www.iianc.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.iianc.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.iianc.com.\n",
      "Scraping https://www.iianc.com/marketing-solutions.\n",
      "Scraping https://www.iianc.com/staffing-solutions.\n",
      "Scraping https://www.iianc.com/advertising-solutions.\n",
      "Scraping https://www.iianc.com/market-access-solutions.\n",
      "Rate limit exceeded. Retrying after 59.999999046325684 seconds.\n",
      "Scraping https://www.iianc.com/independent-market-solutions.\n",
      "Scraping https://www.iianc.com/eo-insurance-professional-liability-products.\n",
      "Scraping https://www.iianc.com/technology-solutions.\n",
      "Scraping https://www.iianc.com/marketing-solutions/real-grader.\n",
      "Scraping https://www.iianc.com/staffing-solutions/insuracademy-graduates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:  40%|████      | 42/104 [07:39<28:10, 27.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.wolferesearch.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.wolferesearch.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.wolferesearch.com.\n",
      "Rate limit exceeded. Retrying after 59.999999046325684 seconds.\n",
      "Scraping https://www.wolferesearch.com/wolfeservices/.\n",
      "Scraping https://www.wolferesearch.com/executionservices/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:  42%|████▏     | 44/104 [08:56<31:04, 31.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.loanpass.io\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.loanpass.io'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.loanpass.io.\n",
      "Scraping https://www.loanpass.io/partners.\n",
      "Scraping https://www.loanpass.io/solutions.\n",
      "Scraping https://www.loanpass.io/services.\n",
      "Rate limit exceeded. Retrying after 59.999999046325684 seconds.\n",
      "Scraping https://www.loanpass.io/product-and-pricing-engine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:  45%|████▌     | 47/104 [10:16<27:39, 29.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.docmagic.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.docmagic.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.docmagic.com.\n",
      "Scraping https://www.docmagic.com/product-training.\n",
      "Scraping https://www.docmagic.com/professional-services.\n",
      "Scraping https://www.docmagic.com/data-services.\n",
      "Scraping https://www.docmagic.com/third-party-services.\n",
      "Rate limit exceeded. Retrying after 59.999996185302734 seconds.\n",
      "Scraping https://www.docmagic.com/integration-services.\n",
      "Scraping https://www.docmagic.com/esignature-platforms.\n",
      "Scraping https://www.docmagic.com/settlement-services.\n",
      "Scraping https://www.docmagic.com/esign-platform.\n",
      "Scraping https://www.docmagic.com/partners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:  46%|████▌     | 48/104 [11:59<38:52, 41.66s/it]/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.upstart.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Scraping data:  47%|████▋     | 49/104 [11:59<30:49, 33.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.upstart.com\n",
      "Failed to access https://www.upstart.com. Status code: 403\n",
      "Company Upstart has error: object of type 'NoneType' has no len()\n",
      "https://www.willowservicing.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.willowservicing.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.willowservicing.com.\n",
      "Rate limit exceeded. Retrying after 59.99999737739563 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping data:  47%|████▋     | 49/104 [12:51<14:26, 15.75s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/UCL DSML/Thesis/project/firecrawl_scraping.py:105\u001b[0m, in \u001b[0;36mcrawl_data\u001b[0;34m(base_url, url_list, file_path, overwrite)\u001b[0m\n\u001b[1;32m    103\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m current_dateTime\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Etc/GMT\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 105\u001b[0m scraped_data \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpageOptions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43monlyMainContent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Check if 'markdown' key exists in the scraped data\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/firecrawl/firecrawl.py:91\u001b[0m, in \u001b[0;36mFirecrawlApp.scrape_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscrape URL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/firecrawl/firecrawl.py:317\u001b[0m, in \u001b[0;36mFirecrawlApp._handle_error\u001b[0;34m(self, response, action)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# Raise an HTTPError with the custom message and attach the response\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError(message, response\u001b[38;5;241m=\u001b[39mresponse)\n",
      "\u001b[0;31mHTTPError\u001b[0m: Unexpected error during scrape URL: Status code 429. Rate limit exceeded. Consumed points: 6, Remaining points: 0. Upgrade your plan at https://firecrawl.dev/pricing for increased rate limits or please retry after 39s, resets at Sun Jul 28 2024 13:14:59 GMT+0000 (Coordinated Universal Time)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(related_urls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m      9\u001b[0m         related_urls \u001b[38;5;241m=\u001b[39m select_urls(related_urls, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcrawl_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelated_urls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscraping_output_v2_raw/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcompany_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprocessed_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompany \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompany\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/UCL DSML/Thesis/project/firecrawl_scraping.py:116\u001b[0m, in \u001b[0;36mcrawl_data\u001b[0;34m(base_url, url_list, file_path, overwrite)\u001b[0m\n\u001b[1;32m    114\u001b[0m     rate_limit_reset_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetry-After\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m60\u001b[39m)) \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRate limit exceeded. Retrying after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrate_limit_reset_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrate_limit_reset_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Skip the rest of the code in this iteration and retry scraping the same URL\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "client_data = read_json_file('client_info.json')\n",
    "for company, company_info in tqdm(client_data.items(), desc=\"Scraping data\", position=0, leave=True):\n",
    "    base_url = company_info['url']\n",
    "    if not base_url:\n",
    "        continue\n",
    "    try:\n",
    "        all_urls, related_urls = get_related_urls(base_url)\n",
    "        if len(related_urls) > 10:\n",
    "            related_urls = select_urls(related_urls, 10)\n",
    "        result = crawl_data(base_url, related_urls, f'scraping_output_v2_raw/{company_info[\"processed_name\"]}.json', overwrite=False)\n",
    "    except Exception as e:\n",
    "        print(f'Company {company} has error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bloomberg.com/professional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.bloomberg.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/urllib3/connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.bloomberg.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'https://www.bloomberg.com/feedback',\n",
       "  'https://www.bloomberg.com/notices/tos'},\n",
       " ['https://www.bloomberg.com/professional'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_related_urls('https://www.bloomberg.com/professional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.hubsync.com',\n",
       " 'https://www.hubsync.com/solutions#engagement-letter-wizard',\n",
       " 'https://www.hubsync.com/solutions#efile',\n",
       " 'https://www.hubsync.com/solutions#esign',\n",
       " 'https://www.hubsync.com/solutions#workflow-tracking',\n",
       " 'https://www.hubsync.com/solutions#client-portal-delivery',\n",
       " 'https://www.hubsync.com/solutions',\n",
       " 'https://www.hubsync.com/solutions#planning-analytics',\n",
       " 'https://www.hubsync.com/solutions',\n",
       " 'https://www.hubsync.com/solutions#hubsync-gateway']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
