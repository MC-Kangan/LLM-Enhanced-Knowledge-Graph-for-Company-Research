{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firecrawl import FirecrawlApp\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "import json \n",
    "import pandas as pd \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(url):\n",
    "    load_dotenv()\n",
    "    # Initialize the FirecrawlApp with your API key\n",
    "    app = FirecrawlApp(api_key=os.getenv('FIRECRAWL_KEY'))\n",
    "    \n",
    "    # Scrape a single URL\n",
    "    scraped_data = app.scrape_url(url,{'pageOptions':{'onlyMainContent': True}})\n",
    "    \n",
    "    # Check if 'markdown' key exists in the scraped data\n",
    "    if 'markdown' in scraped_data:\n",
    "        return scraped_data['markdown']\n",
    "    else:\n",
    "        raise KeyError(\"The key 'markdown' does not exist in the scraped data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_raw_data(raw_data, timestamp, output_folder='scraping_output'):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the raw markdown data with timestamp in filename\n",
    "    raw_output_path = os.path.join(output_folder, f'rawData_{timestamp}.md')\n",
    "    with open(raw_output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(raw_data)\n",
    "    print(f\"Raw data saved to {raw_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(data, fields=None):\n",
    "    load_dotenv()\n",
    "    # Instantiate the OpenAI client\n",
    "    client = OpenAI(api_key=os.getenv('OPENAI_KEY'))\n",
    "\n",
    "    # Assign default fields if not provided\n",
    "    if fields is None:\n",
    "        fields = [\"Address\", \"Real Estate Agency\", \"Price\", \"Beds\", \"Baths\", \"Sqft\", \"Home Type\", \"Listing Age\", \"Picture of home URL\", \"Listing URL\"]\n",
    "\n",
    "    # Define system message content\n",
    "    system_message = f\"\"\"You are an intelligent text extraction and conversion assistant. Your task is to extract structured information \n",
    "                        from the given text and convert it into a pure JSON format. The JSON should contain only the structured data extracted from the text, \n",
    "                        with no additional commentary, explanations, or extraneous information. \n",
    "                        You could encounter cases where you can't find the data of the fields you have to extract or the data will be in a foreign language.\n",
    "                        Please process the following text and provide the output in pure JSON format with no words before or after the JSON:\"\"\"\n",
    "\n",
    "    # Define user message content\n",
    "    user_message = f\"Extract the following information from the provided text:\\nPage content:\\n\\n{data}\\n\\nInformation to extract: {fields}\"\n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_message\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_message\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Check if the response contains the expected data\n",
    "    if response and response.choices:\n",
    "        formatted_data = response.choices[0].message.content.strip()\n",
    "        print(f\"Formatted data received from API: {formatted_data}\")\n",
    "\n",
    "        try:\n",
    "            parsed_json = json.loads(formatted_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON decoding error: {e}\")\n",
    "            print(f\"Formatted data that caused the error: {formatted_data}\")\n",
    "            raise ValueError(\"The formatted data could not be decoded into JSON.\")\n",
    "        \n",
    "        return parsed_json\n",
    "    else:\n",
    "        raise ValueError(\"The OpenAI API response did not contain the expected choices data.\")\n",
    "    \n",
    "\n",
    "def save_formatted_data(formatted_data, timestamp, output_folder='output'):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the formatted data as JSON with timestamp in filename\n",
    "    output_path = os.path.join(output_folder, f'sorted_data_{timestamp}.json')\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(formatted_data, f, indent=4)\n",
    "    print(f\"Formatted data saved to {output_path}\")\n",
    "\n",
    "    # Check if data is a dictionary and contains exactly one key\n",
    "    if isinstance(formatted_data, dict) and len(formatted_data) == 1:\n",
    "        key = next(iter(formatted_data))  # Get the single key\n",
    "        formatted_data = formatted_data[key]\n",
    "\n",
    "    # Convert the formatted data to a pandas DataFrame\n",
    "    df = pd.DataFrame(formatted_data)\n",
    "\n",
    "    # Convert the formatted data to a pandas DataFrame\n",
    "    if isinstance(formatted_data, dict):\n",
    "        formatted_data = [formatted_data]\n",
    "\n",
    "    df = pd.DataFrame(formatted_data)\n",
    "\n",
    "    # Save the DataFrame to an Excel file\n",
    "    excel_output_path = os.path.join(output_folder, f'sorted_data_{timestamp}.xlsx')\n",
    "    df.to_excel(excel_output_path, index=False)\n",
    "    print(f\"Formatted data saved to Excel at {excel_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.trulia.com/CA/San_Francisco/'\n",
    "\n",
    "try:\n",
    "    # Generate timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Scrape data\n",
    "    raw_data = scrape_data(url)\n",
    "    \n",
    "    # Save raw data\n",
    "    save_raw_data(raw_data, timestamp)\n",
    "    \n",
    "    # Format data\n",
    "    formatted_data = format_data(raw_data)\n",
    "    \n",
    "    # Save formatted data\n",
    "    save_formatted_data(formatted_data, timestamp)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = scrape_data('https://www.estimize.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[![Logo](https://ucarecdn.com/64603bc8-776c-4912-bb3b-25887fcc958a/)](/)\n",
      "\n",
      "*   *   [Login](/users/sign_in)\n",
      "        \n",
      "    \n",
      "\n",
      "*   *   [Login](/users/sign_in)\n",
      "        \n",
      "    \n",
      "\n",
      "The Most Accurate Earnings Estimates Dataset on the Planet\n",
      "==========================================================\n",
      "\n",
      "Estimize crowdsources earnings and macroeconomic estimates from over 120,000 contributors across the globe. We welcome anyone to contribute in return for free access to our data and analytics tools, or you can simply pay now to subscribe.Â \n",
      "\n",
      "Learn more below\n",
      "\n",
      "*   [Free Contributor Account](/users/sign_up)\n",
      "    \n",
      "*   [Premium 21-day Free Trial](/premium)\n",
      "    \n",
      "\n",
      "![](https://www.estimize.com/images/macbook-mockup-shadow.png)\n",
      "\n",
      "*   70% Win Rate\n",
      "    \n",
      "    The Estimize Consensus has been closer to the company's actual reported results 70% of the time compared to legacy sell-side only estimate data sets.\n",
      "    \n",
      "*   2x Deeper\n",
      "    \n",
      "    More than 2x the number of estimates per earnings release on average, wider estimate dispersion and 3x the average number of revisions per estimate.\n",
      "    \n",
      "*   10+ years of Data\n",
      "    \n",
      "    Through bull and bear markets our data set continues to outperform. Its superiority is confirmed in more than a dozen published academic papers.\n",
      "    \n",
      "\n",
      "How the Estimize Platform Works\n",
      "-------------------------------\n",
      "\n",
      "Estimize is designed to collect opinions from the widest possible range of contributors, while maintaining the highest quality data through advanced behavioral and statistical algorithms.\n",
      "\n",
      "*   ![](https://www.estimize.com/assets/page_landing/screenshots/landing-slider-1a-21488bb9ada0711ebe01d1c6e03913b1.png)\n",
      "*   ![](https://www.estimize.com/assets/page_landing/screenshots/landing-slider-1b-00fd4007bf49d31bbabf37fac20ae766.png)\n",
      "*   ![](https://www.estimize.com/assets/page_landing/screenshots/landing-slider-1c-7537de17a901ce78b4dc76bdf17949f5.png)\n",
      "\n",
      "*   ### \n",
      "    \n",
      "    Contribute Anonymously\n",
      "    \n",
      "    Our contributors are a broad mix of buy-side, independent, and sell-side investment professionals, along with amateur analysts, independent investors, and academics. While we do ask which of these categories you belong to, any contributor can choose to remain anonymous as they publish their estimates.\n",
      "    \n",
      "*   ### \n",
      "    \n",
      "    Give-to-get\n",
      "    \n",
      "    Contributors gain free access to Estimize data for each earnings release they estimate on. Each stock allows estimation on EPS and Revenue. Some stocks also have a key performance indicator such as same store sales, monthly active users or product segment revenue.\n",
      "    \n",
      "\n",
      "*   ### \n",
      "    \n",
      "    Quality Control and Smart Consensus\n",
      "    \n",
      "    Advanced algorithms monitor contributor behavior and assess the validity of each estimate to prevent erroneous data from entering the consensus. Each estimate is then weighted based on our proprietary Select Consensus model.\n",
      "    \n",
      "*   ### \n",
      "    \n",
      "    Alerts, Screening, Excel files\n",
      "    \n",
      "    Smart data viz to help you make more informed estimates, automated alerts to leverage the Estimize data for better investment decisions. Advanced screening to find the data you need. Daily Excel file via email. Leaderboards and user profile to track your accuracy.\n",
      "    \n",
      "\n",
      "*   ![](https://www.estimize.com/assets/page_landing/screenshots/landing-slider-2a-c598aad7ddedd7018bdb3bcb333af481.png)\n",
      "*   ![](https://www.estimize.com/assets/page_landing/screenshots/landing-slider-2b-a3457cc9971026ee47025c006ca184dd.png)\n",
      "*   ![](https://www.estimize.com/assets/page_landing/screenshots/landing-slider-2c-4a114b8bac677dd5261bf40a70674c3f.png)\n",
      "*   ![](https://www.estimize.com/assets/page_landing/screenshots/landing-slider-2d-4abca5896d9c6e8606fbb699f2d15550.png)\n",
      "*   ![](https://www.estimize.com/assets/page_landing/screenshots/landing-slider-2e-e660772c774e0495730a200c4b1706b6.png)\n",
      "*   ![](https://www.estimize.com/assets/page_landing/screenshots/landing-slider-2f-6e5b85c33795902300c37065b1dedb95.png)\n",
      "*   ![](https://www.estimize.com/assets/page_landing/screenshots/landing-slider-2g-c9776c274af4337f18125d0d0101d7ef.png)\n",
      "\n",
      "Subscribe Now For Full Access\n",
      "-----------------------------\n",
      "\n",
      "|     | ### Contributor<br><br>Access Estimize data for companies you contribute estimates to for FREE<br><br>$<br><br>0<br><br>/ month<br><br>$<br><br>/year | ### Subscriber<br><br>Full access to data and advanced tools for individuals without contributing estimates<br><br>$<br><br>99<br><br>/ month<br><br>$<br><br>999<br><br>/year | ### Institutional<br><br>Access our raw data feeds plus scaled pricing<br><br>  <br><br>QUOTATION<br><br>$<br><br>/year |\n",
      "| --- | --- | --- | --- |\n",
      "| Daily Email Alerts | ![â](https://www.estimize.com/images/checked--acid.svg) | ![â](https://www.estimize.com/images/checked--acid.svg) | ![â](https://www.estimize.com/images/checked--acid.svg) |\n",
      "| Advanced Screening | ![â](https://www.estimize.com/images/checked--acid.svg) | ![â](https://www.estimize.com/images/checked--acid.svg) | ![â](https://www.estimize.com/images/checked--acid.svg) |\n",
      "| Unblinded Access | ![â](https://www.estimize.com/images/cross--red.svg) | ![â](https://www.estimize.com/images/checked--acid.svg) | ![â](https://www.estimize.com/images/checked--acid.svg) |\n",
      "| Daily Excel Files | ![â](https://www.estimize.com/images/cross--red.svg) | ![â](https://www.estimize.com/images/cross--red.svg) | ![â](https://www.estimize.com/images/checked--acid.svg) |\n",
      "| Factor Models | ![â](https://www.estimize.com/images/cross--red.svg) | ![â](https://www.estimize.com/images/cross--red.svg) | ![â](https://www.estimize.com/images/checked--acid.svg) |\n",
      "| API/FTP Access | ![â](https://www.estimize.com/images/cross--red.svg) | ![â](https://www.estimize.com/images/cross--red.svg) | ![â](https://www.estimize.com/images/checked--acid.svg) |\n",
      "| Premium Support | ![â](https://www.estimize.com/images/cross--red.svg) | ![â](https://www.estimize.com/images/cross--red.svg) | ![â](https://www.estimize.com/images/checked--acid.svg) |\n",
      "|     | [Sign up now](/users/sign_up) | [Subscribe Now](/premium) | [Contact Us](/contact) |\n",
      "\n",
      "Industry and Academic Research Into the Estimize Dataset\n",
      "--------------------------------------------------------\n",
      "\n",
      "![Penn university](https://www.estimize.com/assets/page_partners/penn-university-805ca91399c4cef57a486bc3eb9223f5.png)\n",
      "\n",
      "_\"We find that Estimize-covered firms still meet or beat analyst earnings expectations in over 70% of firm-quarters.\"  \n",
      "  \n",
      "_\n",
      "\n",
      "**SANDRA SCHAFHAUTLE, UNIVERSITY OF PENNSYLVANIA**\n",
      "\n",
      "[Read the full paper here](https://s3.amazonaws.com/com.estimize.public/papers/23+08+Crowdsourced+Forecasts+and+the+Market+Reaction.pdf)\n",
      "\n",
      "![Temple university 2](https://www.estimize.com/assets/page_partners/temple-university-2-f2023f1e0eeddb7ece7be30e42aa8426.png)\n",
      "\n",
      "_\"Estimize strives to improve consensus forecast accuracy by relying on the \"wisdom of crowds,\", which improves predictive accuracy by reducing idiosyncratic error.\"  \n",
      "  \n",
      "_\n",
      "\n",
      "LAWRENCE D. BROWN, TEMPLE UNIVERSITY\n",
      "\n",
      "[Read the full paper here](https://s3.amazonaws.com/com.estimize.public/papers/23+06+Nudging+Towards+Better+Earnings+Forecasts.pdf)\n",
      "\n",
      "![University of kentucky 2](https://www.estimize.com/assets/page_partners/university-of-kentucky-2-01a49532e5bb45d452aa9ba25160cb85.png)\n",
      "\n",
      "_\"We find that firms added to Estimize... experience a pervasive and substantial reduction in consensus bias and a limited increase in consensus accuracy relative to matched control firms.\"_\n",
      "\n",
      "RUSSEL JAME, UNIVERSITY OF KENTUCKY\n",
      "\n",
      "[Read the full paper here](https://s3.amazonaws.com/com.estimize.public/papers/21+08+Can+FinTech+Competition+Improve+Sell-side+Research+Quality_.pdf)\n",
      "\n",
      "![G washington university 2](https://www.estimize.com/assets/page_partners/g-washington-university-2-107afdc308f9c7a08bf397a1bddd287a.png)\n",
      "\n",
      "_\"Estimize provides a less biased, more accurate, and more representative view of market expectations compared to sell-side consensus forecasts compromised by severe biases.\"_\n",
      "\n",
      "EDWARD SUL, GEORGE WASHINGTON UNIVERSITY\n",
      "\n",
      "[Read the full paper here](https://s3.amazonaws.com/com.estimize.public/papers/20+04+Effects+of+FinTech+and+Crowdsourced+Forecasting+on+Firms_+Evidence+from+Estimize.pdf+.pdf)\n",
      "\n",
      "![Temple university 2](https://www.estimize.com/assets/page_partners/temple-university-2-f2023f1e0eeddb7ece7be30e42aa8426.png)\n",
      "\n",
      "_\"Analysts benefit from the visibility afforded by Estimize by experiencing favorable career outcomes.\"  \n",
      "  \n",
      "_\n",
      "\n",
      "JOSHUA A. KHAVIS, TEMPLE UNIVERSITY\n",
      "\n",
      "[Read the full paper here](https://s3.amazonaws.com/com.estimize.public/papers/19+12+Do+Analysts+Benefit+from+Online+Feedback+and+Visibility_.pdf)\n",
      "\n",
      "![Mckinley research 2](https://www.estimize.com/assets/page_partners/mckinley-research-2-82f726b77c78a84defa8a5d6783b6ee4.png)\n",
      "\n",
      "_\"Estimize data appears to contain unique and valuable preearnings and post-earnings announcement information.\"_\n",
      "\n",
      "ROBERT A. GILLIAM, MCKINLEY CAPITAL RESEARCH\n",
      "\n",
      "[Read the full paper here](https://s3.amazonaws.com/com.estimize.public/papers/17+07+Improving+Earnings+Forecasts+with+Estimize+Crowd+Sourced+Data+by+McKinley.pdf)\n",
      "\n",
      "![Wolfe research 2](https://www.estimize.com/assets/page_partners/wolfe-research-2-e748815ca125b5b22c407f405e134de0.png)\n",
      "\n",
      "_\"We find Estimize estimates to be not only more accurate and timelier than the sell-side, but also highly complementary to traditional factors.\"_\n",
      "\n",
      "SHENG WANG, WOLFE RESEARCH\n",
      "\n",
      "[Read the full paper here](https://s3.amazonaws.com/com.estimize.public/papers/17+04+Crowdsourcing+Earnings+and+Revenue+Estimates+by+Wolfe+Research.pdf)\n",
      "\n",
      "![University of kentucky 2](https://www.estimize.com/assets/page_partners/university-of-kentucky-2-01a49532e5bb45d452aa9ba25160cb85.png)\n",
      "\n",
      "_\"We find that Estimize forecasts are incrementally useful in forecasting earnings and measuring the market's expectations of earnings.\"_\n",
      "\n",
      "RUSSEL JAME, UNIVERSITY OF KENTUCKY\n",
      "\n",
      "[Read the full paper here](https://s3.amazonaws.com/com.estimize.public/papers/16+03+The+Value+of+Crowdsourced+Earnings+Forecasts.pdf)\n",
      "\n",
      "![Deutsche bank 2](https://www.estimize.com/assets/page_partners/deutsche-bank-2-56cd65b6f18342c0395ecc6285c94e18.png)\n",
      "\n",
      "_\"We find that the timelier Estimize forecasts can more accurately identify earnings surprise which results in a greater capture of the post earnings drift.\"_\n",
      "\n",
      "SHENG WANG, DEUTSCHE BANK MARKETS RESEARCH\n",
      "\n",
      "[Read the full paper here](https://s3.amazonaws.com/com.estimize.public/papers/14+03+The+Wisdom+of+Crowds_+Crowdsourcing+Earnings+Estimates+by+DeutscheBank.pdf)\n",
      "\n",
      "API & FTP Data Access\n",
      "---------------------\n",
      "\n",
      "Whether youâre a systematic quantitative hedge fund, the developer of an exciting new fintech app, or an academic looking to do research, you can easily access our historical data files or live API for 30 days to test before you purchase an institutional data license. Visit our institutional data sales page for more details.\n",
      "\n",
      "*   [Learn more](/sales)\n",
      "    \n",
      "\n",
      "![](https://ucarecdn.com/1aea4c04-964d-464a-a963-2ce29971009e/-/crop/1666x947/0,162/-/preview/image.png)\n",
      "\n",
      "Interactive Widget\n",
      "------------------\n",
      "\n",
      "Help your website users make better investment decisions with the Estimize widget. Add this small widget to leverage the collective wisdom of crowds and receive highly accurate earnings predictions for U.S. equities.\n",
      "\n",
      "*   [Learn more](/widget-demo)\n",
      "    \n",
      "\n",
      "![Widget demo image](https://www.estimize.com/assets/page_home/widget-demo-image-aabff65473fd10cd7bf11f42f0857ce9.png) \n",
      "\n",
      "...Access to Our Data Through Other Top Financial Platforms\n",
      "-----------------------------------------------------------\n",
      "\n",
      "We have partnered with some of the biggest Financial Platforms in the world to make Estimize data available\n",
      "\n",
      "*   ![](https://ucarecdn.com/a7a714d1-112e-40df-827b-74c7ff92a352/image.png)\n",
      "*   ![](https://ucarecdn.com/835cf912-9dc6-4932-aafb-dd071fb81fd8/image.png)\n",
      "*   ![](https://ucarecdn.com/eeab4075-2f8d-4599-b10f-0ec791cec25f/image.png)\n",
      "*   ![](https://ucarecdn.com/3a0876f1-393a-4aef-9214-2b5fbb35c2c3/image.png)\n",
      "*   ![](https://ucarecdn.com/9e3b8fda-f752-4d69-82f8-e79cb5e7831e/image.png)\n",
      "*   ![](https://ucarecdn.com/6a5aec8b-7095-4185-bad1-c9291e2d0c38/image.png)\n",
      "\n",
      "Â©\n",
      "\n",
      "2024 Estimize. All Rights Reserved. Estimize is owned and operated by ExtractAlpha.\n",
      "\n",
      "[![](https://www.estimize.com/images/extractalpha-logo-horiz-white.png)](https://www.extractalpha.com/?__hstc=11750891.b49dfb8f4248fe8ccfafa37c94f3c884.1719759458870.1719759458870.1719759458870.1&__hssc=11750891.1.1719759458871&__hsfp=651967898)\n",
      "\n",
      "*   [![](https://www.estimize.com/images/twitter.svg)](https://twitter.com/Estimize)\n",
      "    \n",
      "*   [![](https://www.estimize.com/images/linkedin.svg)](https://www.linkedin.com/company/estimize/)\n",
      "    \n",
      "*   [![](https://www.estimize.com/images/link.svg)](https://stocktwits.com/Estimize)\n",
      "Raw data saved to scraping_output/rawData_20240630_230026.md\n"
     ]
    }
   ],
   "source": [
    "print(raw_data)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "save_raw_data(raw_data, timestamp, output_folder='scraping_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product_offering': {'Earnings Estimates Dataset': 'Crowdsources earnings and macroeconomic estimates from over 120,000 contributors. Features include a 70% win rate, 2x deeper estimates, and over 10 years of data.', 'Estimize Platform': 'Collects opinions from a wide range of contributors using advanced behavioral and statistical algorithms. Features include anonymous contribution, give-to-get model, quality control, smart consensus, alerts, screening, and Excel files.'}, 'partners': {'University of Pennsylvania': 'Research on Estimize-covered firms meeting or beating analyst earnings expectations.', 'Temple University': 'Research on improving consensus forecast accuracy using the wisdom of crowds.', 'University of Kentucky': 'Research on reducing consensus bias and increasing consensus accuracy.', 'George Washington University': 'Research on providing a less biased and more accurate view of market expectations.', 'McKinley Capital Research': 'Research on unique and valuable pre-earnings and post-earnings announcement information.', 'Wolfe Research': 'Research on the accuracy and timeliness of Estimize estimates.', 'Deutsche Bank Markets Research': 'Research on identifying earnings surprises and capturing post-earnings drift.'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage \n",
    "\n",
    "\n",
    "system_message_1 = \"\"\"\n",
    "\n",
    "            You are an intelligent text extraction and conversion assistant. Your task is to extract structured information \n",
    "            from the given text and convert it into a pure JSON format. \n",
    "            The JSON should contain only the structured data extracted from the text, with no additional commentary, explanations, or extraneous information. \n",
    "            You could encounter cases where you can't find the data of the fields you have to extract.\n",
    "            Please process the following text and provide the output in pure JSON format with no words before or after the JSON:\n",
    "            \"\"\"\n",
    "            \n",
    "system_message_2 = \"\"\"          \n",
    "            Extract the following information from the text extracted from a webpage of a company:\n",
    "\n",
    "            ## 1. Product offering:\n",
    "               - What service or product does the company provide?\n",
    "               - What features does the product or service have?\n",
    "\n",
    "            ## 2. Client or partnership:\n",
    "               - Who are the partners or clients of the company?\n",
    "               - What are the clients or partners use this product for?\n",
    "\n",
    "            Output in JSON format:\n",
    "            {{\n",
    "                \"product_offering\": {{\n",
    "                    \"product_1\": \"concise features description of the product or service\",\n",
    "                    \"product_2\": \"concise features description of the product or service\",\n",
    "                    ...\n",
    "                }}\n",
    "                \"partners\": {{\n",
    "                    \"partner_name_1\": \"description of the usecase\",\n",
    "                    \"partner_name_2\": \"description of the usecase\",\n",
    "                    ...\n",
    "                }}\n",
    "            }}\n",
    "\n",
    "            Here are the rules that you need to adhere:\n",
    "            ## Rules:\n",
    "               - The aim is to achieve simplicity and clarity in the extracted text.\n",
    "               - Make sure to answer in the correct JSON format.\n",
    "               - If no information is provided for any of the fields, return nothing of that field.\n",
    "               - DO NOT HALLUCINATE.\n",
    "            \"\"\"\n",
    "            \n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_message_1),\n",
    "        (\"system\", system_message_2),\n",
    "        (\"human\", \"Use the given text to extract information: {input}\"),\n",
    "        (\"human\", \"Tip: Make sure to answer in the correct JSON format\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=os.getenv('OPENAI_KEY'),\n",
    "                 temperature = 0, \n",
    "                 model_name = \"gpt-4o\")\n",
    "\n",
    "llm_chain = prompt | llm | SimpleJsonOutputParser()\n",
    "\n",
    "response = llm_chain.invoke({'input': raw_data})\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to output.json\n"
     ]
    }
   ],
   "source": [
    "# Save the response dictionary to a JSON file\n",
    "output_file = \"output.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(response, f, indent=4)\n",
    "\n",
    "print(f\"Output saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
