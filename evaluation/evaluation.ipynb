{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenkangan/Documents/UCL DSML/Thesis/project/ucl_project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage \n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from os.path import exists\n",
    "import os\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.schema import StrOutputParser\n",
    "import json\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This notebook evaluates the performance of three LLMs, gpt4o, gpt4o-mini, gpo-3.5-turbo on a product attribute-value extraction task with zero-shot setting.\n",
    "\n",
    "The aim is to use the test result as a benchmark for the actual information extraction chain for knowledge graph construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define utility function\n",
    "def read_jsonl_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return [json.loads(line) for line in file if line.strip()]\n",
    "    \n",
    "\n",
    "def write_jsonl_file(file_path, data):\n",
    "    # Open the file in write mode ('w')\n",
    "    with open(file_path, 'w') as file:\n",
    "        for item in data:\n",
    "            # Serialize the dictionary to a JSON formatted string\n",
    "            json_str = json.dumps(item)\n",
    "            # Write the JSON string to the file followed by a newline\n",
    "            file.write(json_str + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_jsonl_file('final_target_scores.jsonl')\n",
    "\n",
    "jewelry = [product for product in data if product['category'] == 'Jewelry']\n",
    "office = [product for product in data if product['category'] == 'Office Products']\n",
    "food = [product for product in data if product['category'] == 'Grocery And Gourmet Food']\n",
    "home_garden = [product for product in data if product['category'] == 'Home And Garden']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product attribute-value extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "class ProductInfoGarden(BaseModel):\n",
    "   Base: Optional[str] = Field(default=None, alias='Base')\n",
    "   Capacity: Optional[str] = Field(default=None, alias='Capacity')\n",
    "   Color: Optional[str] = Field(default=None, alias='Color')\n",
    "   Cooling: Optional[str] = Field(default=None, alias='Cooling')\n",
    "   Depth: Optional[str] = Field(default=None, alias='Depth')\n",
    "   Gauge: Optional[str] = Field(default=None, alias='Gauge')\n",
    "   Heat: Optional[str] = Field(default=None, alias='Heat')\n",
    "   Height: Optional[str] = Field(default=None, alias='Height')\n",
    "   Length: Optional[str] = Field(default=None, alias='Length')\n",
    "   Manufacturer: Optional[str] = Field(default=None, alias='Manufacturer')\n",
    "   Manufacturer_Stock_Number: Optional[str] = Field(default=None, alias='Manufacturer Stock Number')\n",
    "   Material: Optional[str] = Field(default=None, alias='Material')\n",
    "   Product_Type: Optional[str] = Field(default=None, alias='Product Type')\n",
    "   Retail_UPC: Optional[str] = Field(default=None, alias='Retail UPC')\n",
    "   Shape: Optional[str] = Field(default=None, alias='Shape')\n",
    "   Shelves: Optional[str] = Field(default=None, alias='Shelves')\n",
    "   Splash: Optional[str] = Field(default=None, alias='Splash')\n",
    "   Stainless_Steel_Series: Optional[str] = Field(default=None, alias='Stainless Steel Series')\n",
    "   Voltage: Optional[str] = Field(default=None, alias='Voltage')\n",
    "   Width: Optional[str] = Field(default=None, alias='Width')\n",
    "\n",
    "\n",
    "class ProductInfoFood(BaseModel):\n",
    "\n",
    "   Brand: Optional[str] = Field(default=None, alias='Brand')\n",
    "   Flavor: Optional[str] = Field(default=None, alias='Flavor')\n",
    "   Manufacturer_Stock_Number: Optional[str] = Field(default=None, alias='Manufacturer Stock Number')\n",
    "   Pack_Quantity: Optional[str] = Field(default=None, alias='Pack Quantity')\n",
    "   Packing_Type: Optional[str] = Field(default=None, alias='Packing Type')\n",
    "   Product_Type: Optional[str] = Field(default=None, alias='Product Type')\n",
    "   Retail_UPC: Optional[str] = Field(default=None, alias='Retail UPC')\n",
    "   Size_Weight: Optional[str] = Field(default=None, alias='Size/Weight')\n",
    "   \n",
    "   \n",
    "class ProductInfoOffice(BaseModel):\n",
    "   Brand: Optional[str] = Field(default=None, alias='Brand')\n",
    "   Binding: Optional[str] = Field(default=None, alias='Binding')\n",
    "   Capacity: Optional[str] = Field(default=None, alias='Capacity')\n",
    "   Closure: Optional[str] = Field(default=None, alias='Closure')\n",
    "   Colors: Optional[str] = Field(default=None, alias='Color(s)')\n",
    "   Depth: Optional[str] = Field(default=None, alias='Depth')\n",
    "   Height: Optional[str] = Field(default=None, alias='Height')\n",
    "   Length: Optional[str] = Field(default=None, alias='Length')\n",
    "   Width: Optional[str] = Field(default=None, alias='Width')\n",
    "   Mounting: Optional[str] = Field(default=None, alias='Mounting')\n",
    "   Manufacturer_Stock_Number: Optional[str] = Field(default=None, alias='Manufacturer Stock Number')\n",
    "   Material: Optional[str] = Field(default=None, alias='Material')\n",
    "   Product_Type: Optional[str] = Field(default=None, alias='Product Type')\n",
    "   Retail_UPC: Optional[str] = Field(default=None, alias='Retail UPC')\n",
    "   Page_Yield: Optional[str] = Field(default=None, alias='Page Yield')\n",
    "   Paper_Weight: Optional[str] = Field(default=None, alias='Paper Weight')\n",
    "   Sheet_Perforation: Optional[str] = Field(default=None, alias='Sheet Perforation')\n",
    "   Pack_Quantity: Optional[str] = Field(default=None, alias='Pack_Quantity')\n",
    "   \n",
    "class ProductInfoJewelry(BaseModel):\n",
    "   Brand: Optional[str] = Field(default=None, alias='Brand')\n",
    "   Gender: Optional[str] = Field(default=None, alias='Gender')\n",
    "   Metal_Type: Optional[str] = Field(default=None, alias='Metal Type')\n",
    "   Model_Number: Optional[str] = Field(default=None, alias='Model Number')\n",
    "   Product_Type: Optional[str] = Field(default=None, alias='Product Type')\n",
    "   Stone_Shape: Optional[str] = Field(default=None, alias='Stone Shape')\n",
    "   Stones_Setting: Optional[str] = Field(default=None, alias='Stones Setting')\n",
    "   Stones_Total_Weight: Optional[str] = Field(default=None, alias='Stones Total Weight')\n",
    "   Stones_Type: Optional[str] = Field(default=None, alias='Stones Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_extraction(text: str, custom_extraction_prompt:str, model_name: str = 'gpt-4o') -> ProductInfoGarden:\n",
    "    \n",
    "    # Patch the OpenAI client with Instructor\n",
    "    client = instructor.from_openai(OpenAI(api_key=os.getenv('OPENAI_KEY')))\n",
    "    \n",
    "    system_message = \"\"\"\n",
    "    You are an intelligent text extraction and conversion assistant. Your task is to extract structured information \n",
    "    from the given text and convert it into a structured format. \n",
    "    The output response should contain only the data extracted from the text, with no additional commentary, explanations, or extraneous information.\n",
    "    If the required information could not be found from the given source, return nothing for that field. Do not hallucinate.\n",
    "    \"\"\"\n",
    "    \n",
    "    rule_prompt = \"\"\"\n",
    "                Here are the rules that you need to adhere:\n",
    "                    ## Rules:\n",
    "                    - The aim is to achieve simplicity and clarity in the extracted text.\n",
    "                    - Make sure to answer in the structured format.\n",
    "                    - If no information is provided for any of the fields, return nothing of that field.\n",
    "                    - DO NOT HALLUCINATE.\n",
    "                \"\"\"\n",
    "    \n",
    "    extraction_prompt = f\"\"\"\n",
    "    {system_message}\n",
    "    {custom_extraction_prompt}\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name, \n",
    "        response_model=ProductInfoGarden,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": extraction_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Use the given text to extract information: {text}\"},\n",
    "            {\"role\": \"user\", \"content\": rule_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def evaluate_extraction(my_output, expected_output):\n",
    "    \n",
    "    # Simplify the expected output by removing the details of pid and score and handling multiple valid options\n",
    "    simplified_expected_output = {'target_scores': {}}\n",
    "\n",
    "    for field, values in expected_output['target_scores'].items():\n",
    "        if isinstance(values, dict):  # Check if the value is a dictionary (implying multiple values)\n",
    "            # Extract keys and make them a list if there are multiple valid responses\n",
    "            simplified_expected_output['target_scores'][field] = list(values.keys())\n",
    "        else:\n",
    "            # Directly assign if it is a single value\n",
    "            simplified_expected_output['target_scores'][field] = values\n",
    "    \n",
    "    target_scores = simplified_expected_output['target_scores']\n",
    "    total_fields = len(target_scores)  # Total fields to be extracted\n",
    "    correct_matches = 0  # Count of correctly extracted fields\n",
    "    incorrect_fields = []  # List to store names of fields that are incorrect\n",
    "\n",
    "    for field, expected_values in target_scores.items():\n",
    "        # Normalize the value from my_output\n",
    "        field = field.replace(' ', '_')\n",
    "        field = field.replace('/', '_')\n",
    "        field = field.replace('(', '')\n",
    "        field = field.replace(')', '')\n",
    "        my_value = my_output.get(field, 'n/a') if my_output.get(field) is not None else 'n/a'\n",
    "        my_value = my_value.lower()  # Convert to lower case for case insensitive comparison\n",
    "\n",
    "        # Handle cases where multiple correct answers are expected\n",
    "        if isinstance(expected_values, list):\n",
    "            # Normalize all expected values for case-insensitive comparison\n",
    "            expected_values_normalized = [value.lower() for value in expected_values]\n",
    "            if my_value in expected_values_normalized:\n",
    "                correct_matches += 1\n",
    "            else:\n",
    "                incorrect_fields.append(field)\n",
    "        else:  # Single correct answer case\n",
    "            expected_value_normalized = expected_values.lower()\n",
    "            if my_value == expected_value_normalized:\n",
    "                correct_matches += 1\n",
    "            else:\n",
    "                incorrect_fields.append(field)\n",
    "\n",
    "    accuracy_percentage = (correct_matches / total_fields) * 100\n",
    "\n",
    "    # Print fields that were incorrect\n",
    "    if incorrect_fields:\n",
    "        print(\"Incorrect fields:\")\n",
    "        for field in incorrect_fields:\n",
    "            print(f\"- {field}\")\n",
    "\n",
    "    return accuracy_percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "accuracy_list = []\n",
    "model_name = 'gpt-4o-mini' #'gpt-3.5-turbo'\n",
    "dataset = 'garden'\n",
    "\n",
    "for index in tqdm(range(0, 100)):\n",
    "    result = {}\n",
    "    data = home_garden[index]\n",
    "    result['id'] = data['id']\n",
    "    result['cluster_id'] = data['cluster_id']\n",
    "    result['category'] = data['category']\n",
    "    text_compile = f'title: {data[\"input_title\"]}\\ndescription: {data[\"input_description\"]}'\n",
    "\n",
    "    custom_extraction_prompt = \"\"\"\n",
    "        Extract information from the text extracted from a webpage of a product, including title and description:\n",
    "        Output in a structured format.\n",
    "        \"\"\"\n",
    "    response = initial_extraction(text_compile, custom_extraction_prompt, model_name)\n",
    "    result['output'] = response.dict()\n",
    "    accuracy = evaluate_extraction(response.dict(), data)\n",
    "    result['accuracy'] = accuracy\n",
    "    result_list.append(result)\n",
    "    accuracy_list.append(accuracy)\n",
    "print(f'Average accuracy: {sum(accuracy_list)/len(accuracy_list)}')\n",
    "\n",
    "# Specify the file path for your JSON Lines file\n",
    "file_path = f'{model_name.replace(\".\", \"-\")}-{dataset}-zero.jsonl'\n",
    "\n",
    "write_jsonl_file(file_path, result_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test results\n",
    "- garden - gpt3.5 - zero - 75.65\n",
    "- garden - gpt4o - zero - 81.2\n",
    "- garden - gpt4o-mini - zero - 62.30\n",
    "\n",
    "- food - gpt3.5 - zero - 70.22\n",
    "- food - gpt4o - zero - 77.62\n",
    "- food - gpt4o-mini - zero - 74.07\n",
    "\n",
    "- office - gpt3.5 - zero - 76.94\n",
    "- office - gpt4o - zero - 78.11\n",
    "- office - gpt4o-mini - zero - 76.06\n",
    "\n",
    "- jewelry - gpt3.5 - zero - 76.78\n",
    "- jewelry - gpt4o - zero - 84.56\n",
    "- jewelry - gpt4o-mini - zero - 82.33\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
